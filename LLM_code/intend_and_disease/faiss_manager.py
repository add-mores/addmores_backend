# /faiss_manager.py
"""
FAISS ì¸ë±ìŠ¤ ì €ì¥/ë¡œë“œ ë§¤ë‹ˆì €
exaone_v6.txt ê¸°ë°˜ - ê¸°ì¡´ RAGIndexManager í™•ì¥
"""

import os
import json
import faiss
import pickle
import numpy as np
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Optional, Tuple, Any
import logging

logger = logging.getLogger(__name__)

class FAISSIndexSaver:
    """
    FAISS ì¸ë±ìŠ¤ ì €ì¥/ë¡œë“œ ê´€ë¦¬ì
    - ê¸°ì¡´ exaone_v6 ì½”ë“œì˜ ëª¨ë“  ì¸ë±ìŠ¤ë¥¼ ë””ìŠ¤í¬ì— ì €ì¥
    - ì„œë²„ ì¬ì‹œì‘ ì‹œ ë¹ ë¥¸ ë¡œë“œë¡œ ì„±ëŠ¥ í–¥ìƒ
    """
    
    def __init__(self, index_dir: str = "data/indexes"):
        """
        Args:
            index_dir: ì¸ë±ìŠ¤ ì €ì¥ ë””ë ‰í† ë¦¬
        """
        self.index_dir = Path(index_dir)
        self.index_dir.mkdir(parents=True, exist_ok=True)
        
        # ì¸ë±ìŠ¤ íŒŒì¼ ê²½ë¡œ
        self.paths = {
            # RAG ì¸ë±ìŠ¤ë“¤
            'qa_index': self.index_dir / 'qa_index.faiss',
            'medical_doc_index': self.index_dir / 'medical_doc_index.faiss',
            
            # ì§ˆë³‘ ì¸ë±ìŠ¤ë“¤  
            'disease_key_index': self.index_dir / 'disease_key_index.faiss',
            'disease_full_index': self.index_dir / 'disease_full_index.faiss',
            
            # ì˜ì•½í’ˆ ì¸ë±ìŠ¤
            'medication_index': self.index_dir / 'medication_index.faiss',
            
            # ë©”íƒ€ë°ì´í„°
            'qa_documents': self.index_dir / 'qa_documents.pkl',
            'medical_documents': self.index_dir / 'medical_documents.pkl',
            'disease_metadata': self.index_dir / 'disease_metadata.pkl',
            'medication_metadata': self.index_dir / 'medication_metadata.pkl',
            'hospital_data': self.index_dir / 'hospital_data.pkl',
            
            # ì‹œìŠ¤í…œ ì •ë³´
            'index_info': self.index_dir / 'index_info.json'
        }
        
        logger.info(f"ğŸ“ FAISS ì¸ë±ìŠ¤ ì €ì¥ì†Œ ì´ˆê¸°í™”: {self.index_dir}")

    def save_all_indexes(self, rag_manager, disease_key_index, disease_full_index, 
                        disease_metadata, medication_index, medication_metadata, hospital_data):
        """
        ëª¨ë“  FAISS ì¸ë±ìŠ¤ì™€ ë©”íƒ€ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥
        exaone_v6.txtì˜ ëª¨ë“  ë°ì´í„° êµ¬ì¡° ì§€ì›
        """
        
        try:
            save_start = datetime.now()
            logger.info("ğŸ’¾ ì „ì²´ ì¸ë±ìŠ¤ ì €ì¥ ì‹œì‘...")
            
            # 1) RAG ì¸ë±ìŠ¤ ì €ì¥
            self._save_rag_indexes(rag_manager)
            
            # 2) ì§ˆë³‘ ì¸ë±ìŠ¤ ì €ì¥
            self._save_disease_indexes(disease_key_index, disease_full_index, disease_metadata)
            
            # 3) ì˜ì•½í’ˆ ì¸ë±ìŠ¤ ì €ì¥
            self._save_medication_index(medication_index, medication_metadata)
            
            # 4) ë³‘ì› ë°ì´í„° ì €ì¥
            self._save_hospital_data(hospital_data)
            
            # 5) ì¸ë±ìŠ¤ ì •ë³´ ì €ì¥
            self._save_index_info()
            
            save_time = (datetime.now() - save_start).total_seconds()
            logger.info(f"âœ… ì „ì²´ ì¸ë±ìŠ¤ ì €ì¥ ì™„ë£Œ! ({save_time:.2f}ì´ˆ)")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ ì¸ë±ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False

    def _save_rag_indexes(self, rag_manager):
        """RAG ì¸ë±ìŠ¤ ì €ì¥ (qa_index, medical_doc_index)"""
        
        # Q&A ì¸ë±ìŠ¤
        if rag_manager.qa_index is not None:
            faiss.write_index(rag_manager.qa_index, str(self.paths['qa_index']))
            logger.info(f"ğŸ’¾ Q&A ì¸ë±ìŠ¤ ì €ì¥: {self.paths['qa_index']}")
        
        # ì˜ë£Œ ë¬¸ì„œ ì¸ë±ìŠ¤
        if rag_manager.medical_doc_index is not None:
            faiss.write_index(rag_manager.medical_doc_index, str(self.paths['medical_doc_index']))
            logger.info(f"ğŸ’¾ ì˜ë£Œë¬¸ì„œ ì¸ë±ìŠ¤ ì €ì¥: {self.paths['medical_doc_index']}")
        
        # RAG ë¬¸ì„œ ë©”íƒ€ë°ì´í„°
        with open(self.paths['qa_documents'], 'wb') as f:
            pickle.dump(rag_manager.qa_documents, f)
        
        with open(self.paths['medical_documents'], 'wb') as f:
            pickle.dump(rag_manager.medical_documents, f)
            
        logger.info(f"ğŸ’¾ RAG ë©”íƒ€ë°ì´í„° ì €ì¥: Q&A {len(rag_manager.qa_documents)}ê°œ, ì˜ë£Œë¬¸ì„œ {len(rag_manager.medical_documents)}ê°œ")

    def _save_disease_indexes(self, key_index, full_index, metadata):
        """ì§ˆë³‘ ì¸ë±ìŠ¤ ì €ì¥ (index_key, index_full, all_docs_meta)"""
        
        # FAISS ì¸ë±ìŠ¤
        if key_index is not None:
            faiss.write_index(key_index, str(self.paths['disease_key_index']))
            logger.info(f"ğŸ’¾ ì§ˆë³‘ í•µì‹¬ì¦ìƒ ì¸ë±ìŠ¤ ì €ì¥: {self.paths['disease_key_index']}")
        
        if full_index is not None:
            faiss.write_index(full_index, str(self.paths['disease_full_index']))
            logger.info(f"ğŸ’¾ ì§ˆë³‘ ì „ì²´ì¦ìƒ ì¸ë±ìŠ¤ ì €ì¥: {self.paths['disease_full_index']}")
        
        # ë©”íƒ€ë°ì´í„°
        with open(self.paths['disease_metadata'], 'wb') as f:
            pickle.dump(metadata, f)
            
        logger.info(f"ğŸ’¾ ì§ˆë³‘ ë©”íƒ€ë°ì´í„° ì €ì¥: {len(metadata)}ê°œ")

    def _save_medication_index(self, med_index, med_metadata):
        """ì˜ì•½í’ˆ ì¸ë±ìŠ¤ ì €ì¥ (meds_index, meds_meta_list)"""
        
        # FAISS ì¸ë±ìŠ¤
        if med_index is not None:
            faiss.write_index(med_index, str(self.paths['medication_index']))
            logger.info(f"ğŸ’¾ ì˜ì•½í’ˆ ì¸ë±ìŠ¤ ì €ì¥: {self.paths['medication_index']}")
        
        # ë©”íƒ€ë°ì´í„°
        with open(self.paths['medication_metadata'], 'wb') as f:
            pickle.dump(med_metadata, f)
            
        logger.info(f"ğŸ’¾ ì˜ì•½í’ˆ ë©”íƒ€ë°ì´í„° ì €ì¥: {len(med_metadata)}ê°œ")

    def _save_hospital_data(self, hospital_data):
        """ë³‘ì› ë°ì´í„° ì €ì¥ (df_hosp)"""
        
        with open(self.paths['hospital_data'], 'wb') as f:
            pickle.dump(hospital_data, f)
            
        logger.info(f"ğŸ’¾ ë³‘ì› ë°ì´í„° ì €ì¥: {len(hospital_data)}ê°œ")

    def _save_index_info(self):
        """ì¸ë±ìŠ¤ ìƒì„± ì •ë³´ ì €ì¥"""
        
        info = {
            'created_at': datetime.now().isoformat(),
            'version': 'exaone_v6_faiss',
            'indexes': {
                'qa_index': self.paths['qa_index'].exists(),
                'medical_doc_index': self.paths['medical_doc_index'].exists(),
                'disease_key_index': self.paths['disease_key_index'].exists(),
                'disease_full_index': self.paths['disease_full_index'].exists(),
                'medication_index': self.paths['medication_index'].exists()
            },
            'metadata_files': {
                'qa_documents': self.paths['qa_documents'].exists(),
                'medical_documents': self.paths['medical_documents'].exists(),
                'disease_metadata': self.paths['disease_metadata'].exists(),
                'medication_metadata': self.paths['medication_metadata'].exists(),
                'hospital_data': self.paths['hospital_data'].exists()
            }
        }
        
        with open(self.paths['index_info'], 'w', encoding='utf-8') as f:
            json.dump(info, f, indent=2, ensure_ascii=False)
            
        logger.info(f"ğŸ’¾ ì¸ë±ìŠ¤ ì •ë³´ ì €ì¥: {self.paths['index_info']}")

    def load_all_indexes(self):
        """
        ì €ì¥ëœ ëª¨ë“  ì¸ë±ìŠ¤ì™€ ë©”íƒ€ë°ì´í„° ë¡œë“œ
        Returns: (rag_data, disease_data, medication_data, hospital_data)
        """
        
        try:
            load_start = datetime.now()
            logger.info("ğŸ“‚ ì €ì¥ëœ ì¸ë±ìŠ¤ ë¡œë“œ ì‹œì‘...")
            
            # ì¸ë±ìŠ¤ ì¡´ì¬ í™•ì¸
            if not self._check_indexes_exist():
                logger.warning("âš ï¸ ì¼ë¶€ ì¸ë±ìŠ¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
            # 1) RAG ì¸ë±ìŠ¤ ë¡œë“œ
            rag_data = self._load_rag_indexes()
            
            # 2) ì§ˆë³‘ ì¸ë±ìŠ¤ ë¡œë“œ
            disease_data = self._load_disease_indexes()
            
            # 3) ì˜ì•½í’ˆ ì¸ë±ìŠ¤ ë¡œë“œ
            medication_data = self._load_medication_index()
            
            # 4) ë³‘ì› ë°ì´í„° ë¡œë“œ
            hospital_data = self._load_hospital_data()
            
            load_time = (datetime.now() - load_start).total_seconds()
            logger.info(f"âœ… ì „ì²´ ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ! ({load_time:.2f}ì´ˆ)")
            
            return {
                'rag': rag_data,
                'disease': disease_data,
                'medication': medication_data,
                'hospital': hospital_data
            }
            
        except Exception as e:
            logger.error(f"âŒ ì¸ë±ìŠ¤ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None

    def _load_rag_indexes(self):
        """RAG ì¸ë±ìŠ¤ ë¡œë“œ"""
        
        rag_data = {}
        
        # FAISS ì¸ë±ìŠ¤ ë¡œë“œ
        if self.paths['qa_index'].exists():
            rag_data['qa_index'] = faiss.read_index(str(self.paths['qa_index']))
            
        if self.paths['medical_doc_index'].exists():
            rag_data['medical_doc_index'] = faiss.read_index(str(self.paths['medical_doc_index']))
        
        # ë©”íƒ€ë°ì´í„° ë¡œë“œ
        if self.paths['qa_documents'].exists():
            with open(self.paths['qa_documents'], 'rb') as f:
                rag_data['qa_documents'] = pickle.load(f)
                
        if self.paths['medical_documents'].exists():
            with open(self.paths['medical_documents'], 'rb') as f:
                rag_data['medical_documents'] = pickle.load(f)
        
        logger.info("ğŸ“‚ RAG ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ")
        return rag_data

    def _load_disease_indexes(self):
        """ì§ˆë³‘ ì¸ë±ìŠ¤ ë¡œë“œ"""
        
        disease_data = {}
        
        # FAISS ì¸ë±ìŠ¤ ë¡œë“œ
        if self.paths['disease_key_index'].exists():
            disease_data['key_index'] = faiss.read_index(str(self.paths['disease_key_index']))
            
        if self.paths['disease_full_index'].exists():
            disease_data['full_index'] = faiss.read_index(str(self.paths['disease_full_index']))
        
        # ë©”íƒ€ë°ì´í„° ë¡œë“œ
        if self.paths['disease_metadata'].exists():
            with open(self.paths['disease_metadata'], 'rb') as f:
                disease_data['metadata'] = pickle.load(f)
        
        logger.info("ğŸ“‚ ì§ˆë³‘ ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ")
        return disease_data

    def _load_medication_index(self):
        """ì˜ì•½í’ˆ ì¸ë±ìŠ¤ ë¡œë“œ"""
        
        medication_data = {}
        
        # FAISS ì¸ë±ìŠ¤ ë¡œë“œ
        if self.paths['medication_index'].exists():
            medication_data['index'] = faiss.read_index(str(self.paths['medication_index']))
        
        # ë©”íƒ€ë°ì´í„° ë¡œë“œ
        if self.paths['medication_metadata'].exists():
            with open(self.paths['medication_metadata'], 'rb') as f:
                medication_data['metadata'] = pickle.load(f)
        
        logger.info("ğŸ“‚ ì˜ì•½í’ˆ ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ")
        return medication_data

    def _load_hospital_data(self):
        """ë³‘ì› ë°ì´í„° ë¡œë“œ"""
        
        if self.paths['hospital_data'].exists():
            with open(self.paths['hospital_data'], 'rb') as f:
                hospital_data = pickle.load(f)
                
            logger.info("ğŸ“‚ ë³‘ì› ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
            return hospital_data
        
        return None

    def _check_indexes_exist(self):
        """í•„ìˆ˜ ì¸ë±ìŠ¤ íŒŒì¼ë“¤ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸"""
        
        required_files = [
            'qa_index', 'medical_doc_index',
            'disease_key_index', 'disease_full_index', 
            'medication_index'
        ]
        
        missing_files = []
        for file_key in required_files:
            if not self.paths[file_key].exists():
                missing_files.append(file_key)
        
        if missing_files:
            logger.warning(f"âš ï¸ ëˆ„ë½ëœ ì¸ë±ìŠ¤ íŒŒì¼: {missing_files}")
            return False
            
        return True

    def get_index_info(self):
        """ì €ì¥ëœ ì¸ë±ìŠ¤ ì •ë³´ ì¡°íšŒ"""
        
        if self.paths['index_info'].exists():
            with open(self.paths['index_info'], 'r', encoding='utf-8') as f:
                return json.load(f)
        return None

    def clear_all_indexes(self):
        """ëª¨ë“  ì €ì¥ëœ ì¸ë±ìŠ¤ íŒŒì¼ ì‚­ì œ"""
        
        try:
            deleted_count = 0
            for file_path in self.paths.values():
                if file_path.exists():
                    file_path.unlink()
                    deleted_count += 1
            
            logger.info(f"ğŸ—‘ï¸ ì¸ë±ìŠ¤ íŒŒì¼ {deleted_count}ê°œ ì‚­ì œ ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ì¸ë±ìŠ¤ ì‚­ì œ ì‹¤íŒ¨: {e}")
            return False

# =============================================================================
# RAGIndexManager í™•ì¥ í´ë˜ìŠ¤ - ì €ì¥/ë¡œë“œ ê¸°ëŠ¥ ì¶”ê°€
# =============================================================================

class RAGIndexManagerWithStorage:
    """
    ê¸°ì¡´ RAGIndexManagerì— ì €ì¥/ë¡œë“œ ê¸°ëŠ¥ ì¶”ê°€
    exaone_v6.txt ì½”ë“œì™€ ì™„ì „ í˜¸í™˜
    """
    
    def __init__(self, embedding_model, index_dir: str = "data/indexes"):
        # ê¸°ì¡´ ì†ì„±ë“¤
        self.embedding_model = embedding_model
        self.qa_index = None
        self.medical_doc_index = None
        self.qa_documents = []
        self.medical_documents = []
        
        # ì €ì¥ ê´€ë¦¬ì
        self.faiss_saver = FAISSIndexSaver(index_dir)
        
    def load_rag_data(self):
        """
        RAG ë°ì´í„° ë¡œë“œ - ì €ì¥ëœ ì¸ë±ìŠ¤ ìš°ì„  ì‚¬ìš©
        ê¸°ì¡´ exaone_v6.txtì˜ load_rag_data() ë©”ì„œë“œì™€ ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤
        """
        
        # 1) ì €ì¥ëœ ì¸ë±ìŠ¤ê°€ ìˆìœ¼ë©´ ë¡œë“œ
        if self._try_load_saved_indexes():
            logger.info("âœ… ì €ì¥ëœ RAG ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ!")
            return
        
        # 2) ì €ì¥ëœ ì¸ë±ìŠ¤ê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ êµ¬ì¶•
        logger.info("ğŸ“‚ ì €ì¥ëœ ì¸ë±ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œ êµ¬ì¶•í•©ë‹ˆë‹¤...")
        self._load_rag_data_from_csv()
        
        # 3) ìƒˆë¡œ êµ¬ì¶•í•œ ì¸ë±ìŠ¤ ì €ì¥
        self._save_rag_indexes()

    def _try_load_saved_indexes(self):
        """ì €ì¥ëœ RAG ì¸ë±ìŠ¤ ë¡œë“œ ì‹œë„"""
        
        try:
            rag_data = self.faiss_saver._load_rag_indexes()
            
            if rag_data and 'qa_index' in rag_data and 'medical_doc_index' in rag_data:
                self.qa_index = rag_data['qa_index']
                self.medical_doc_index = rag_data['medical_doc_index']
                self.qa_documents = rag_data.get('qa_documents', [])
                self.medical_documents = rag_data.get('medical_documents', [])
                
                logger.info(f"ğŸ“‚ RAG ì¸ë±ìŠ¤ ë¡œë“œ: Q&A {len(self.qa_documents)}ê°œ, ì˜ë£Œë¬¸ì„œ {len(self.medical_documents)}ê°œ")
                return True
                
        except Exception as e:
            logger.warning(f"âš ï¸ ì €ì¥ëœ ì¸ë±ìŠ¤ ë¡œë“œ ì‹¤íŒ¨: {e}")
            
        return False

    def _load_rag_data_from_csv(self):
        """
        CSVì—ì„œ RAG ë°ì´í„° ë¡œë“œ (ê¸°ì¡´ exaone_v6.txt ë¡œì§)
        """
        print("ğŸ”„ RAG ë°ì´í„° ë¡œë”© ì‹œì‘...")
        
        # Q&A ë°ì´í„° ë¡œë“œ (clean_51004.csv)
        self._load_qa_data()
        
        # ì˜ë£Œ ë¬¸ì„œ ë°ì´í„° ë¡œë“œ (ë‚˜ë¨¸ì§€ 5ê°œ clean íŒŒì¼ë“¤)
        self._load_medical_documents()
        
        # ì¸ë±ìŠ¤ êµ¬ì¶•
        self._build_indexes()
        
        print("âœ… RAG ë°ì´í„° ë¡œë”© ì™„ë£Œ!")

    def _save_rag_indexes(self):
        """í˜„ì¬ RAG ì¸ë±ìŠ¤ë“¤ì„ ë””ìŠ¤í¬ì— ì €ì¥"""
        
        try:
            self.faiss_saver._save_rag_indexes(self)
            logger.info("ğŸ’¾ RAG ì¸ë±ìŠ¤ ì €ì¥ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ RAG ì¸ë±ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _build_indexes(self):
        """FAISS ì¸ë±ìŠ¤ êµ¬ì¶• - exaon_v5.txt ì™„ì „ ë™ì¼"""
        print("ğŸ”„ RAG ì¸ë±ìŠ¤ êµ¬ì¶• ì¤‘...")
        
        # Q&A ì¸ë±ìŠ¤ êµ¬ì¶•
        if self.qa_documents:
            qa_embeddings = []
            for doc in self.qa_documents:
                embedding = self.embedding_model.encode([doc.content])[0]
                qa_embeddings.append(embedding)
                doc.embedding = embedding
            
            qa_matrix = np.vstack(qa_embeddings)
            faiss.normalize_L2(qa_matrix)
            
            self.qa_index = faiss.IndexFlatIP(qa_matrix.shape[1])
            self.qa_index.add(qa_matrix)
        
        # ì˜ë£Œ ë¬¸ì„œ ì¸ë±ìŠ¤ êµ¬ì¶•
        if self.medical_documents:
            doc_embeddings = []
            for doc in self.medical_documents:
                embedding = self.embedding_model.encode([doc.content])[0]
                doc_embeddings.append(embedding)
                doc.embedding = embedding
            
            doc_matrix = np.vstack(doc_embeddings)
            faiss.normalize_L2(doc_matrix)
            
            self.medical_doc_index = faiss.IndexFlatIP(doc_matrix.shape[1])
            self.medical_doc_index.add(doc_matrix)
        
        print("âœ… RAG ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ!")
    
    def search_qa(self, query: str, top_k: int = 3):
        """Q&A ê²€ìƒ‰ - exaon_v5.txt ì™„ì „ ë™ì¼"""
        if not self.qa_index or not self.qa_documents:
            return []
        
        query_embedding = self.embedding_model.encode([query])
        faiss.normalize_L2(query_embedding)
        
        scores, indices = self.qa_index.search(query_embedding, top_k)
        
        results = []
        for idx in indices[0]:
            if 0 <= idx < len(self.qa_documents):
                results.append(self.qa_documents[idx])
        
        return results
    
    def search_medical_docs(self, query: str, top_k: int = 3):
        """ì˜ë£Œ ë¬¸ì„œ ê²€ìƒ‰ - exaon_v5.txt ì™„ì „ ë™ì¼"""
        if not self.medical_doc_index or not self.medical_documents:
            return []
        
        query_embedding = self.embedding_model.encode([query])
        faiss.normalize_L2(query_embedding)
        
        scores, indices = self.medical_doc_index.search(query_embedding, top_k)
        
        results = []
        for idx in indices[0]:
            if 0 <= idx < len(self.medical_documents):
                results.append(self.medical_documents[idx])
        
        return results
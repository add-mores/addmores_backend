"""
RAG-ì˜ë£Œ ì±—ë´‡  (Geo-Filter + ìƒí™œíƒœê·¸ ê°•í™” Â· LangChain 0.2+)

â— disease / medicine / hospital â†’ ê°ê¸° ì¸ë±ìŠ¤ ìºì‹±
â— ë„¤ì´ë²„ ì§€ì˜¤ì½”ë”© + í•˜ë²„ì‚¬ì¸ ë°˜ê²½ 5 kmë¡œ â€˜ê·¼ì²˜ ë³‘ì›â€™ ìš°ì„  ì„ ë³„
â— medicine ë¬¸ì„œì— â€˜ê°ê¸°/í•´ì—´/ê¸°ì¹¨â€™ íƒœê·¸ ì‚½ì…í•´ ì•½í’ˆ-ë§¤ì¹­ë¥  â†‘
â— HybridGeoRetriever(BaseRetriever) â†’ RetrievalQA í†µê³¼
"""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0. ë¼ì´ë¸ŒëŸ¬ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€
from langchain_ollama                       import OllamaLLM
from langchain_core.documents               import Document
from langchain_core.retrievers              import BaseRetriever
from langchain_community.vectorstores       import FAISS
from langchain_community.embeddings         import HuggingFaceEmbeddings
from langchain.text_splitter                import RecursiveCharacterTextSplitter
from langchain.chains                       import RetrievalQA
from langchain.prompts                      import (
    ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate,
)
from pydantic                                import ConfigDict
import pandas as pd, os, csv, re, math, requests
from datetime                                import datetime

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. ì„¤ì • & ìœ í‹¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€
# â€¼ï¸ ë‘ ì´ë¦„ ëª¨ë‘ ì½ì–´ API í‚¤ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
NAVER_MAP_ID = (
    os.getenv("NAVER_MAP_ID")
    or os.getenv("NEXT_PUBLIC_MAP_CLIENT_ID")
)
NAVER_MAP_SECRET = (
    os.getenv("NAVER_MAP_SECRET")
    or os.getenv("NEXT_PUBLIC_MAP_CLIENT_SECRET")
)

LOG = lambda m: print(f"ğŸ•’ {datetime.now().strftime('%H:%M:%S')} | {m}")

def pretty(txt: str):
    print(re.sub(r'\n{2,}', '\n\n', txt.replace("\\n", "\n")).strip())

def haversine(lat1, lon1, lat2, lon2):
    R = 6371
    dlat, dlon = map(math.radians, [lat2 - lat1, lon2 - lon1])
    a = (math.sin(dlat/2)**2 +
         math.cos(math.radians(lat1))*math.cos(math.radians(lat2))*math.sin(dlon/2)**2)
    return 2 * R * math.atan2(math.sqrt(a), math.sqrt(1 - a))

def normalize_addr(addr: str):
    return re.sub(r'ë¡œ(\d)', r'ë¡œ \1', addr).strip()

def geocode_naver(addr: str):
    if not (NAVER_MAP_ID and NAVER_MAP_SECRET):
        raise RuntimeError("âŒ NAVER API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    url = "https://maps.apigw.ntruss.com/map-geocode/v2/geocode"
    headers = {
        "X-NCP-APIGW-API-KEY-ID": NAVER_MAP_ID,
        "X-NCP-APIGW-API-KEY":    NAVER_MAP_SECRET,
    }
    res = requests.get(url, headers=headers, params={"query": addr}, timeout=10)
    res.raise_for_status()
    items = res.json().get("addresses", [])
    if not items:
        raise RuntimeError("âŒ ì§€ì˜¤ì½”ë”© ì‹¤íŒ¨: ê²°ê³¼ ì—†ìŒ")
    return float(items[0]["y"]), float(items[0]["x"])   # lat, lon

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. CSV â†’ Documents & ì¸ë±ìŠ¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€
def load_csv(path: str, label: str):
    df = pd.read_csv(path, quoting=csv.QUOTE_MINIMAL,
                     encoding="utf-8", on_bad_lines="skip")
    docs = []
    for _, row in df.iterrows():
        content = "\n".join(f"{c}: {row[c]}" for c in df.columns)

        # ì•½í’ˆ ë¬¸ì„œ ìƒí™œíƒœê·¸
        if label == "medicine":
            lc = content.lower()
            tags = []
            if any(k in lc for k in ["ê°ê¸°", "ì½§ë¬¼", "ê¸°ì¹¨"]): tags.append("ê°ê¸°")
            if any(k in lc for k in ["í•´ì—´", "ë°œì—´"]):         tags.append("í•´ì—´")
            if tags:
                content = f"tags: {' '.join(tags)}\n" + content

        docs.append(
            Document(
                page_content=content,
                metadata={
                    "source_file": label,
                    **({"lat": row["lat"], "lon": row["lon"]} if "lat" in df else {})
                },
            )
        )
    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    return splitter.split_documents(docs), df

embeds = HuggingFaceEmbeddings(model_name="madatnlp/km-bert")

def build_index(idx_dir, csv_path, label):
    if os.path.isdir(idx_dir):
        return FAISS.load_local(
            idx_dir, embeds, allow_dangerous_deserialization=True
        )
    docs, _ = load_csv(csv_path, label)
    vs = FAISS.from_documents(docs, embeds)
    vs.save_local(idx_dir)
    return vs

disease_vs  = build_index("idx_disease",  "Ragfile/dis.csv",  "disease")
medicine_vs = build_index("idx_medicine", "Ragfile/medi.csv", "medicine")
hospital_docs, hospital_df = load_csv("Ragfile/hospi.csv", "hospital")
hospital_vs = build_index("idx_hospital", "Ragfile/hospi.csv", "hospital")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. HybridGeoRetriever â”€â”€â”€â”€â”€â”€â”€â”€â”€
class HybridGeoRetriever(BaseRetriever):
    k: int = 7
    model_config = ConfigDict(extra="allow")

    def __init__(self, k_each=7):
        super().__init__(k=k_each)

    # ì¢Œí‘œ ì¶”ì¶œ
    def _get_coord(self, query: str):
        m = re.search(r'([0-9]+\.[0-9]+)[ ,]+([0-9]+\.[0-9]+)', query)
        if m:
            return float(m.group(1)), float(m.group(2))
        if "ë¡œ" in query or "ê¸¸" in query:
            try:
                return geocode_naver(normalize_addr(query))
            except Exception as e:
                LOG(str(e))
        return None, None

    # ë™ê¸° ê²€ìƒ‰
    def _get_relevant_documents(self, query, *, run_manager=None, **kw):
        lat, lon = self._get_coord(query)
        docs = []

        # ë³‘ì› í›„ë³´ (ì¢Œí‘œ ìˆìœ¼ë©´ ê±°ë¦¬ ê¸°ë°˜, ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸)
        k_hos = self.k if lat else 2
        if lat:
            sub = hospital_df.copy()
            sub["dist"] = sub.apply(
                lambda r: haversine(lat, lon, r["lat"], r["lon"]), axis=1
            )
            near = sub.nsmallest(k_hos, "dist")
            for _, r in near.iterrows():
                docs.append(
                    Document(
                        page_content="\n".join(f"{c}: {r[c]}" for c in hospital_df.columns),
                        metadata={
                            "source_file": "hospital",
                            "lat": r["lat"],
                            "lon": r["lon"],
                            "dist_km": round(r["dist"], 2),
                        },
                    )
                )
        else:
            docs += hospital_vs.similarity_search(query, k_hos)

        # ì§ˆë³‘Â·ì•½ ë¬¸ì„œ
        docs += disease_vs.similarity_search(query, self.k)
        docs += medicine_vs.similarity_search(query, self.k)
        return docs

    async def _aget_relevant_documents(self, query, *, run_manager=None, **kw):
        return self._get_relevant_documents(query)

retriever = HybridGeoRetriever(k_each=7)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4. RAG í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€
def rag_answer(question: str) -> str:
    llm = OllamaLLM(model="exaone3.5:7.8b", temperature=0.1, num_predict=1024)

    sys_msg = (
        "ë„ˆëŠ” ì˜ë£Œ ì •ë³´ ì±—ë´‡ì´ì•¼. source_file=disease/medicine/hospital.\n"
        "ì¦ìƒÂ·ì§ˆë³‘ ì§ˆë¬¸ì´ë©´ disease/medicineì„ ìš°ì„  ìš”ì•½í•˜ê³ , "
        "ë³‘ì› ì§ˆë¬¸ì´ë©´ ì´ë¯¸ ê±°ë¦¬ í•„í„°ë§ëœ hospital ë¬¸ì„œë§Œ ì´ìš©í•´ ì¶”ì²œí•´ë¼.\n"
        "ë³‘ì› ì¶œë ¥ ì‹œ hos_typeì€ 'ë³‘ì›'ìœ¼ë¡œ, ì§„ë£Œê³¼ëª©ë„ ë³´ì—¬ì¤˜ë¼.\n"
        "ì •ë³´ê°€ ì—†ìœ¼ë©´ 'ì˜ ëª¨ë¥´ê² ìŠµë‹ˆë‹¤'ë¼ê³  ë‹µí•´."
    )

    prompt = ChatPromptTemplate.from_messages(
        [
            SystemMessagePromptTemplate.from_template(sys_msg),
            HumanMessagePromptTemplate.from_template(
                "ì§ˆë¬¸: {question}\n\nì°¸ê³  ë¬¸ì„œ:\n\n{context}"
            ),
        ]
    )

    qa = RetrievalQA.from_chain_type(
        llm=llm,
        retriever=retriever,
        return_source_documents=False,
        chain_type_kwargs={"prompt": prompt},
    )

    res = qa.invoke({"query": question})
    return res["result"] if isinstance(res, dict) else str(res)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5. CLI â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    while True:
        q = input("\nğŸ’¬ ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? (exit/ì¢…ë£Œ)\n> ").strip()
        if q.lower() in {"exit", "ì¢…ë£Œ", "quit"}:
            print("ğŸ‘‹ ê°ì‚¬í•©ë‹ˆë‹¤!"); break
        try:
            pretty(rag_answer(q))
        except Exception as e:
            LOG(f"âŒ ì˜¤ë¥˜: {e}")

from fastapi import APIRouter, HTTPException, Query
from pydantic import BaseModel
from typing import List, Optional
from langchain_community.llms import Ollama
from langchain.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
import difflib
import re

router = APIRouter()

# ëª¨ë¸ ë° ë²¡í„° DB ë¡œë”©
embedding_model_name = "madatnlp/km-bert"
faiss_index_path = "./app/api/medi_faiss_index"
embeddings = HuggingFaceEmbeddings(model_name=embedding_model_name)
vectordb = FAISS.load_local(faiss_index_path, embeddings, allow_dangerous_deserialization=True)
retriever = vectordb.as_retriever(search_type="similarity", search_kwargs={"k": 5})
llm = Ollama(model="exaone3.5:7.8b", temperature=0.1, num_predict=1024)

all_item_names = list({doc.metadata["item_name"] for doc in vectordb.docstore._dict.values()})

class RecommendationRequest(BaseModel):
    query: str
    age_group: Optional[str] = None 
    is_pregnant: Optional[bool] = False
    chronic_conditions: Optional[List[str]] = []

WARNING_MSG = "\n---\n\u26a0\ufe0f ì´ ë‹µë³€ì€ ì°¸ê³ ìš©ì…ë‹ˆë‹¤. ì‹¤ì œ ë³µìš© ì „ì—ëŠ” ë°˜ë“œì‹œ ë³‘ì› ì§„ë£Œë¥¼ ë°›ê±°ë‚˜ ì•½ì‚¬ì™€ ìƒë‹´ì„ í†µí•´ ì²˜ë°©ë°›ìœ¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n---"


def create_context(docs):
    items_list_str = "\n".join([f"- {doc.metadata['item_name']}" for doc in docs])
    context = "\n\n".join([
        f"ì•½ ì´ë¦„: {doc.metadata.get('item_name', 'N/A')}\n"
        f"íš¨ëŠ¥: {doc.metadata.get('efficacy', 'N/A')}\n"
        f"ë³µìš©ë²•: {doc.metadata.get('dosage', 'N/A')}\n"
        f"ì£¼ì˜ì‚¬í•­: {doc.metadata.get('precautions', 'N/A')}\n"
        f"ë¶€ì‘ìš©: {doc.metadata.get('side_effects', 'N/A')}"
        for doc in docs
    ])
    return items_list_str, context


def find_mentioned_item_name(query, item_names):
    sorted_names = sorted(item_names, key=len, reverse=True)
    for name in sorted_names:
        if name in query:
            return name
    return None


def find_similar_item_name(query, item_names, cutoff=0.6):
    words = re.findall(r'\w+', query)
    all_matches = []
    postpositions_to_remove = ["ì´ë‘", "ë‘", "ì²˜ëŸ¼", "í•˜ê³ "]
    for word in words:
        for postposition in postpositions_to_remove:
            if word.endswith(postposition):
                word = word[:-len(postposition)]
                break
        matches = difflib.get_close_matches(word, item_names, n=5, cutoff=cutoff)
        all_matches.extend(matches)
    return list(dict.fromkeys(all_matches))


def condition_filter(doc, age_group, is_pregnant, chronic_conditions):
    text = f"{doc.metadata.get('precautions', '')} {doc.metadata.get('side_effects', '')}"
    age_keywords = {
        'ì†Œì•„': ['ì†Œì•„', 'ì–´ë¦°ì´', 'ìœ ì•„', 'ì˜ì•„', 'ì•„ë™'],
        'ì²­ì†Œë…„': ['ì²­ì†Œë…„', '10ëŒ€', '10ì„¸', 'ì‹­ëŒ€'],
        'ì„±ì¸': ['ì„±ì¸'],
        'ë…¸ì¸': ['ë…¸ì¸', 'ê³ ë ¹ì']
    }
    if age_group and age_group != 'ì„±ì¸':
        for keyword in age_keywords.get(age_group, [age_group]):
            if keyword in text:
                return False
    if is_pregnant and any(word in text for word in ['ì„ì‚°ë¶€', 'ì„ì‹ ', 'ì„ë¶€']):
        return False
    for disease in chronic_conditions:
        if disease and disease in text:
            return False
    return True


@router.post("/llm/medicine")
def recommend_medicine(req: RecommendationRequest):
    query = req.query.strip()
    
    # 1) ì¦ìƒ ê¸°ë°˜ ì¶”ì²œ : ì¿¼ë¦¬ê°€ "ì¦ìƒì€ ..." ìœ¼ë¡œ ì‹œì‘í•˜ë©´ ì¦ìƒ ì¶”ì²œ ë¡œì§ ì‹¤í–‰
    if query.startswith("ì¦ìƒì€"):
        # 1-1) ì—°ë ¹ëŒ€, ì„ì‹ , ê¸°ì €ì§ˆí™˜ ì •ë³´ê°€ ëª¨ë‘ ì—†ìœ¼ë©´ ì•ˆë‚´ ë©”ì‹œì§€
        if (not req.age_group or req.age_group.strip() == "") and not req.is_pregnant and not req.chronic_conditions:
            return {
                "message": "ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì—°ë ¹ëŒ€, ì„ì‹  ì—¬ë¶€, ê¸°ì €ì§ˆí™˜ ì •ë³´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.",
                "need_conditions": True
            }

        symptom_text = query[len("ì¦ìƒì€"):].strip()
        # ë¨¼ì € 5ê°œë§Œ ê²€ìƒ‰
        docs = vectordb.similarity_search(symptom_text, k=5)
        filtered_docs = [doc for doc in docs if condition_filter(doc, req.age_group, req.is_pregnant, req.chronic_conditions)]
        
        # ì¡°ê±´ì— ë§ëŠ” ì•½ì´ ì—†ìœ¼ë©´ 50ê°œë¡œ ë‹¤ì‹œ ê²€ìƒ‰
        if not filtered_docs:
            docs = vectordb.similarity_search(symptom_text, k=50)
            filtered_docs = [doc for doc in docs if condition_filter(doc, req.age_group, req.is_pregnant, req.chronic_conditions)]
        
        if not filtered_docs:
            raise HTTPException(status_code=404, detail="ì¡°ê±´ì— ë§ëŠ” ì˜ì•½í’ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
				
        items_list_str, context = create_context(filtered_docs)
        prompt = f"""
ë‹¹ì‹ ì€ ìˆ™ë ¨ëœ ì•½ì‚¬ì´ë©°, ì¼ë°˜ì˜ì•½í’ˆì— ëŒ€í•œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì‚¬ìš©ìì˜ ì¦ìƒì— ëŒ€í•´ ì•„ë˜ ì•½ ëª©ë¡ ì¤‘ì—ì„œ ì ì ˆí•œ ì•½ì„ ìµœëŒ€ 3ê°œê¹Œì§€ ì¶”ì²œí•˜ì‹­ì‹œì˜¤.
ë°˜ë“œì‹œ ì•„ë˜ ì•½ ëª©ë¡ì— ìˆëŠ” ì•½ë§Œ ì¶”ì²œí•´ì•¼ í•©ë‹ˆë‹¤.

ì‚¬ìš©ì ì •ë³´:
- ì—°ë ¹ëŒ€: {req.age_group}
- ì„ì‹  ì—¬ë¶€: {'ì˜ˆ' if req.is_pregnant else 'ì•„ë‹ˆì˜¤'}
- ê¸°ì €ì§ˆí™˜: {', '.join(req.chronic_conditions) if req.chronic_conditions else 'ì—†ìŒ'}

---

ì•½ ëª©ë¡:
{items_list_str}

ì•½ ì •ë³´:
{context}

ì‚¬ìš©ì ì¦ìƒ: {req.query}
"""
        return {"result": llm.invoke(prompt) + WARNING_MSG}
        
    # 2) ì•½ ì´ë¦„ ê¸°ë°˜ ì¶”ì²œ (ì¦ìƒê¸°ë°˜ ì•„ë‹ˆë©´ ì´ìª½)
    item_name = find_mentioned_item_name(query, all_item_names)
    if not item_name:
        close_matches = find_similar_item_name(query, all_item_names)
        if close_matches:
            # ìœ ì‚¬ ì•½ ì œì•ˆ: ìœ ì‚¬ì•½ ë¦¬ìŠ¤íŠ¸ë¥¼ ë¦¬í„´í•´ì„œ í”„ë¡ íŠ¸ì— ë³´ì—¬ì¤„ ìˆ˜ë„ ìˆìŒ
            return {
                "message": "ì…ë ¥í•˜ì‹  ì•½ê³¼ ë¹„ìŠ·í•œ ì•½ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤. ì•„ë˜ ì¤‘ ì„ íƒí•´ì£¼ì„¸ìš”.",
                "similar_medicines": close_matches
            }
        else:
            # ì•½ ì´ë¦„, ìœ ì‚¬ì•½ ì—†ìœ¼ë©´ ì¦ìƒê¸°ë°˜ ì¶”ì²œë„ ê°™ì´ ì•ˆë‚´í•  ìˆ˜ë„ ìˆìŒ
            return {
                "message": "í•´ë‹¹ ì•½ ì´ë¦„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¦ìƒ ê¸°ë°˜ ê²€ìƒ‰ì„ ì›í•˜ì‹œë©´ 'ì¦ìƒì€ ...' ìœ¼ë¡œ ì‹œì‘í•˜ì—¬ ê²€ìƒ‰í•´ì£¼ì„¸ìš”."
            }

    # item_name ì´ í™•ì •ë˜ë©´ í•´ë‹¹ ì•½ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    base_docs = [doc for doc in vectordb.docstore._dict.values() if doc.metadata.get("item_name") == item_name]
    if not base_docs:
        raise HTTPException(status_code=404, detail="í•´ë‹¹ ì•½ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    base_doc = base_docs[0]

    # 3) ìœ ì‚¬ ì•½ ì¶”ì²œ ìš”ì²­ ì²˜ë¦¬ ("ìœ ì‚¬", "ë¹„ìŠ·", "ëŒ€ì²´" ë‹¨ì–´ í¬í•¨ ì‹œ)
    if any(k in query for k in ["ìœ ì‚¬", "ë¹„ìŠ·", "ëŒ€ì²´"]):
        base_vector = embeddings.embed_query(base_doc.page_content)
        similar_docs = vectordb.similarity_search_by_vector(base_vector, k=10)
        filtered_similar_docs = [d for d in similar_docs if condition_filter(d, req.age_group, req.is_pregnant, req.chronic_conditions) and d.metadata.get("item_name") != item_name]
        similar_items = [d.metadata.get("item_name") for d in filtered_similar_docs][:3]
        similar_metas = [d.metadata for d in filtered_similar_docs][:3]
				
        if not similar_items:
            return {"message": "ì¡°ê±´ì— ë§ëŠ” ìœ ì‚¬ ì•½ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
         

        prompt = f"""
ë‹¹ì‹ ì€ ì „ë¬¸ ì•½ì‚¬ì…ë‹ˆë‹¤.

ì‚¬ìš©ìê°€ ê´€ì‹¬ ìˆëŠ” ì•½ '{item_name}'ê³¼(ì™€) ìœ ì‚¬í•œ ì¼ë°˜ì˜ì•½í’ˆ ìµœëŒ€ 3ê°œë¥¼ ì•„ë˜ ëª©ë¡ì—ì„œ ì¶”ì²œí•´ì£¼ì„¸ìš”.

ğŸ’Š ê¸°ì¤€ ì•½: {item_name}
- ì£¼ìš” íš¨ëŠ¥: {base_doc.metadata.get('efficacy', 'ì •ë³´ ì—†ìŒ')}
- ì£¼ì˜ì‚¬í•­: {base_doc.metadata.get('precautions', 'ì •ë³´ ì—†ìŒ')}

ğŸ’Š ìœ ì‚¬ ì•½ ëª©ë¡:
"""
        for i, meta in enumerate(similar_metas):
            prompt += f"""
{i+1}. ì•½ ì´ë¦„: {similar_items[i]}
- ì£¼ìš” íš¨ëŠ¥: {meta.get('efficacy', 'ì •ë³´ ì—†ìŒ')}
- ì£¼ì˜ì‚¬í•­: {meta.get('precautions', 'ì •ë³´ ì—†ìŒ')}
"""

        prompt += """
ìœ„ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ê° ìœ ì‚¬ ì•½ì´ ê¸°ì¤€ ì•½ê³¼ ì–´ë–¤ ì ì—ì„œ ìœ ì‚¬í•œì§€ ìì—°ìŠ¤ëŸ½ê³  êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
"""
        return {"result": llm.invoke(prompt) + WARNING_MSG}

    # 4) ì¼ë°˜ ì•½ ì •ë³´ ì„¤ëª…
    _, context = create_context(base_docs)
    prompt = f"""
ë‹¹ì‹ ì€ ì „ë¬¸ ì•½ì‚¬ì…ë‹ˆë‹¤.

ì•„ë˜ëŠ” ì¼ë°˜ì˜ì•½í’ˆ '{item_name}' ì— ëŒ€í•œ ì„¤ëª… ìš”ì²­ì…ë‹ˆë‹¤.
ì‚¬ìš©ì ì§ˆë¬¸: {req.query}

[ì°¸ê³  ë¬¸ì„œ]
{context}
"""
    return {"result": llm.invoke(prompt) + WARNING_MSG}

from fastapi import FastAPI, APIRouter, HTTPException
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
import os, json, requests, urllib.parse, re, ast
import numpy as np
from dotenv import load_dotenv
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_ollama import OllamaLLM
import logging

load_dotenv()
# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
)
logger = logging.getLogger(__name__)

NAVER_MAP_ID = os.getenv("NEXT_PUBLIC_MAP_CLIENT_ID")
NAVER_MAP_SECRET = os.getenv("NEXT_PUBLIC_MAP_CLIENT_SECRET")

BASE_DIR = os.path.dirname(__file__)
INDEX_PATH = os.path.join(BASE_DIR, "hospi_faiss_index")
EMBEDDING_MODEL = "madatnlp/km-bert"
llm = OllamaLLM(model="exaone3.5:7.8b", temperature=0.3)
embedding = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)
vectordb = FAISS.load_local(INDEX_PATH, embedding, allow_dangerous_deserialization=True)

router = APIRouter()
app = FastAPI()
app.include_router(router)

def haversine(lat1, lon1, lat2s, lon2s):
    R = 6371
    dlat = np.radians(lat2s - lat1)
    dlon = np.radians(lon2s - lon1)
    a = np.sin(dlat/2)**2 + np.cos(np.radians(lat1)) * np.cos(np.radians(lat2s)) * np.sin(dlon/2)**2
    return R * 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))

def geocode_address(query: str) -> Dict[str, Any]:
    url = "https://maps.apigw.ntruss.com/map-geocode/v2/geocode"
    headers = {
        "X-NCP-APIGW-API-KEY-ID": NAVER_MAP_ID,
        "X-NCP-APIGW-API-KEY": NAVER_MAP_SECRET
    }
    r = requests.get(url, headers=headers, params={"query": query}, timeout=10)
    if r.status_code != 200: raise HTTPException(502, r.text)
    arr = r.json().get("addresses", [])
    if not arr: raise HTTPException(404, "ì£¼ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    a = arr[0]
    return {"lat": float(a["y"]), "lon": float(a["x"]), "address_name": a.get("roadAddress") or a.get("jibunAddress")}

def exaone_chat(msgs: List[Dict[str, Any]]) -> str:
    return llm.invoke(msgs)

def make_web_map_url(name: str) -> str:
    return f"https://map.naver.com/v5/search/{urllib.parse.quote(name)}"

def generate_llm_reason(query: str, hospitals: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    prompt = {"query": query, "candidates": hospitals}
    msgs = [
        {"role": "system", "content":
         "ë‹¤ìŒì€ ì¦ìƒê³¼ ë³‘ì› ì •ë³´ì…ë‹ˆë‹¤. ê° ë³‘ì›ì´ ì™œ ì¶”ì²œë˜ì—ˆëŠ”ì§€ ê°„ë‹¨í•˜ê³  ëª…í™•í•œ ì¶”ì²œ ì‚¬ìœ ë¥¼ JSON ë°°ì—´ë¡œ ìƒì„±í•˜ì„¸ìš”. "
         "ê° í•­ëª©ì€ hos_nmê³¼ reason í•„ë“œë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤. ë§ˆí¬ë‹¤ìš´ê³¼ ì½”ë“œë¸”ë¡ì„ ì“°ì§€ ë§ˆì„¸ìš”."},
        {"role": "user", "content": json.dumps(prompt, ensure_ascii=False)}
    ]
    try:
        raw = exaone_chat(msgs).strip()
        # print("ğŸ§  LLM ì‘ë‹µ ì›ë¬¸:\n", raw)
        logger.info(f"ğŸ§  LLM ì‘ë‹µ ì›ë¬¸:\n{raw}")
        clean = re.sub(r"```(?:json)?\s*(.*?)\s*```", r"\1", raw, flags=re.S).strip()
        if not clean.startswith("["): raise ValueError("ì‘ë‹µì´ JSON ë°°ì—´ ì•„ë‹˜")
        parsed = json.loads(clean)
        hospi_dict = {c["hos_nm"]: c for c in hospitals}
        for item in parsed:
            h = hospi_dict.get(item.get("hos_nm"))
            if h:
                item.setdefault("add", h["add"])
                item.setdefault("deps", h["deps"])
                item.setdefault("distance", h["distance"])
                item.setdefault("opening_hours", "ìš´ì˜ì‹œê°„ ì •ë³´ ì—†ìŒ")
                item.setdefault("map_url", make_web_map_url(item["hos_nm"]))
        return parsed
    except Exception as e:
        # print("âŒ LLM ìš”ì•½ ì‹¤íŒ¨:", e)/
        logger.error(f"âŒ LLM ìš”ì•½ ì‹¤íŒ¨: {e}")
        return [
            {
                "hos_nm": h["hos_nm"],
                "reason": "ì¶”ì²œ ì‚¬ìœ  ì—†ìŒ",
                "add": h.get("add", ""),
                "deps": h.get("deps", []),
                "distance": h.get("distance", 0),
                "opening_hours": h.get("opening_hours", "ìš´ì˜ì‹œê°„ ì •ë³´ ì—†ìŒ"),
                "map_url": make_web_map_url(h["hos_nm"])
            }
            for h in hospitals
        ]

class FilterRequest(BaseModel):
    # í”„ë¡ íŠ¸ì—ì„œ ì£¼ì†Œ(address) ë˜ëŠ” GPS(lat, lon) ì¤‘ í•˜ë‚˜ë§Œ ë³´ë‚´ë„ ë˜ë„ë¡
    address: Optional[str] = None
    lat: Optional[float] = None
    lon: Optional[float] = None
    query: str
    radius: float = 1.0

@router.post("/llm/hospital")
def recommend(req: FilterRequest):
    # ìˆ˜ì •: lat/â€‹lonì´ ë„˜ì–´ì˜¤ë©´ ê·¸ëŒ€ë¡œ ì“°ê³ ,
    #     addressë§Œ ë„˜ì–´ì˜¤ë©´ geocode_address() í˜¸ì¶œ
    if req.lat is not None and req.lon is not None:
        lat, lon = req.lat, req.lon
    elif req.address:
        geo = geocode_address(req.address)
        lat, lon = geo["lat"], geo["lon"]
    else:
        raise HTTPException(400, "address ë˜ëŠ” lat, lon ì¤‘ í•˜ë‚˜ëŠ” ë°˜ë“œì‹œ í•„ìš”í•©ë‹ˆë‹¤.")

    messages = [
        {"role": "system", "content": "ì¦ìƒì—ì„œ ì˜ˆìƒ ì§„ë£Œê³¼ë¥¼ JSON ë°°ì—´ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”. ê° í•­ëª©ì€ {'department': ..., 'score': ...} í˜•ì‹. ë§ˆí¬ë‹¤ìš´ ì—†ì´."},
        {"role": "user", "content": req.query}
    ]
    try:
        resp = exaone_chat(messages).strip()
        # print("ğŸ§  ì˜ˆì¸¡ ì‘ë‹µ:", resp)
        logger.info(f"ğŸ§  ì˜ˆì¸¡ ì‘ë‹µ: {resp}")
        if resp.lstrip().startswith("[{") and "'" in resp:
            preds = ast.literal_eval(resp)
        else:
            preds = json.loads(resp[resp.find("["):resp.rfind("]")+1])
    except Exception as e:
        # print("âŒ ì§„ë£Œê³¼ ì˜ˆì¸¡ ì‹¤íŒ¨:", e)
        logger.error(f"âŒ LLM ìš”ì•½ ì‹¤íŒ¨: {e}")
        
        preds = []

    if not preds:
        return {
            "predicted_deps": [],
            "llm_summary": [],
            "message": "ì…ë ¥í•˜ì‹  ì¦ìƒìœ¼ë¡œëŠ” ì¶”ì²œí•  ìˆ˜ ìˆëŠ” ë³‘ì›ì´ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
        }

    deps = [p["department"].replace(" ", "") for p in preds if "department" in p]
    docs = vectordb.similarity_search(" ".join(deps), k=vectordb.index.ntotal)

    cands = []
    for d in docs:
        m = d.metadata
        lat2, lon2 = float(m.get("lat", 0)), float(m.get("lon", 0))
        dist = haversine(lat, lon, lat2, lon2)
        dep_list = [x.replace(" ", "") for x in m.get("treatment", "").split(",") if x.strip()]
        if any(dep in dep_list for dep in deps):
            cands.append({
                "hos_nm": m.get("hospital_name", ""),
                "add": m.get("address", ""),
                "deps": dep_list,
                "distance": round(dist, 2),
                "lat": lat2,
                "lon": lon2
            })

    cands = sorted(cands, key=lambda x: x["distance"])[:10]

    if not cands:
        all_docs = vectordb.similarity_search("ë³‘ì›", k=vectordb.index.ntotal)
        for d in all_docs:
            m = d.metadata
            lat2, lon2 = float(m.get("lat", 0)), float(m.get("lon", 0))
            dist = haversine(lat, lon, lat2, lon2)
            dep_list = [x.replace(" ", "") for x in m.get("treatment", "").split(",") if x.strip()]
            if any(dep in dep_list for dep in deps):
                cands.append({
                    "hos_nm": m.get("hospital_name", ""),
                    "add": m.get("address", ""),
                    "deps": dep_list,
                    "distance": round(dist, 2),
                    "lat": lat2,
                    "lon": lon2
                })

    summary = generate_llm_reason(req.query, cands)[:3]
    # print(f"âœ… ì¶”ì²œ ë³‘ì› {len(summary)}ê°œ ìƒì„± ì™„ë£Œ")
    logger.info(f"âœ… ì¶”ì²œ ë³‘ì› {len(summary)}ê°œ ìƒì„± ì™„ë£Œ")

    return {
        "predicted_deps": preds,
        "llm_summary": summary
    }

app.include_router(router)
# FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì •

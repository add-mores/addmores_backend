"""
ìˆ˜ì •ëœ í†µí•© ì˜ë£Œ ì±—ë´‡ v6 - ìŠ¤ë§ˆíŠ¸í•œ ì°¨ë³„í™” ì§ˆë¬¸ ì‹œìŠ¤í…œ
ì£¼ìš” ìˆ˜ì •ì‚¬í•­:
1. ì¤‘ë³µ ì§ˆë¬¸ ë°©ì§€ - ì´ë¯¸ ì–¸ê¸‰í•œ ì¦ìƒì€ ë‹¤ì‹œ ë¬»ì§€ ì•ŠìŒ
2. ì„¸ì…˜ ìƒíƒœ ê°œì„  - ì´ˆê¸° ì¦ìƒ ì •ë³´ ìœ ì§€
3. í•„í„°ë§ ë¡œì§ ê°•í™” - ë¹ˆ ê²°ê³¼ ë°©ì§€
4. ì¢…ë£Œ ì¡°ê±´ ê°œì„  - ì ì ˆí•œ ì°¨ë³„í™” ì§ˆë¬¸ ìˆ˜
"""

import os
import sys
import requests
import pandas as pd
import numpy as np
import faiss
import torch
import pickle
import json
from transformers import AutoTokenizer, AutoModel
from typing import List, Dict, Tuple, Optional, Any, Set
import re
import logging
from dataclasses import dataclass
from enum import Enum
import traceback
from datetime import datetime, timedelta

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# =============================================================================
# ğŸš€ FAISS ì¸ë±ìŠ¤ ë¡œë” í´ë˜ìŠ¤ - ê¸°ì¡´ê³¼ ë™ì¼
# =============================================================================

class PreBuiltIndexLoader:
    """ì‚¬ì „ ìƒì„±ëœ FAISS ì¸ë±ìŠ¤ ë¡œë”"""
    
    INDEX_DIR = "faiss_indexes"
    
    INDEX_FILES = {
        "rag_qa": "rag_qa_index.index",
        "rag_medical": "rag_medical_index.index", 
        "disease_key": "disease_key_index.index",
        "disease_full": "disease_full_index.index",
        "medication": "medication_index.index"
    }
    
    METADATA_FILES = {
        "rag_qa": "rag_qa_documents.pkl",
        "rag_medical": "rag_medical_documents.pkl",
        "disease": "disease_metadata.pkl",
        "medication": "medication_metadata.pkl"
    }
    
    CONFIG_FILE = "index_config.json"
    
    @classmethod
    def check_indexes_available(cls) -> bool:
        """ì‚¬ì „ ìƒì„±ëœ ì¸ë±ìŠ¤ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        if not os.path.exists(cls.INDEX_DIR):
            return False
        
        # í•„ìˆ˜ íŒŒì¼ë“¤ ì¡´ì¬ í™•ì¸
        essential_files = [
            cls.INDEX_FILES["rag_qa"],
            cls.INDEX_FILES["rag_medical"],
            cls.METADATA_FILES["rag_qa"], 
            cls.METADATA_FILES["rag_medical"]
        ]
        
        for filename in essential_files:
            if not os.path.exists(os.path.join(cls.INDEX_DIR, filename)):
                logger.warning(f"âš ï¸ í•„ìˆ˜ ì¸ë±ìŠ¤ íŒŒì¼ ëˆ„ë½: {filename}")
                return False
        
        logger.info("âœ… ì‚¬ì „ ìƒì„±ëœ ì¸ë±ìŠ¤ ì‚¬ìš© ê°€ëŠ¥")
        return True
    
    @classmethod
    def load_rag_indexes(cls) -> Tuple[Optional[faiss.Index], Optional[faiss.Index], List, List]:
        """RAG ì¸ë±ìŠ¤ ë¡œë“œ"""
        try:
            logger.info("ğŸ”„ ì‚¬ì „ ìƒì„±ëœ RAG ì¸ë±ìŠ¤ ë¡œë”© ì¤‘...")
            
            # Q&A ì¸ë±ìŠ¤ ë° ë¬¸ì„œ ë¡œë“œ
            qa_index = None
            qa_documents = []
            
            qa_index_path = os.path.join(cls.INDEX_DIR, cls.INDEX_FILES["rag_qa"])
            qa_docs_path = os.path.join(cls.INDEX_DIR, cls.METADATA_FILES["rag_qa"])
            
            if os.path.exists(qa_index_path) and os.path.exists(qa_docs_path):
                qa_index = faiss.read_index(qa_index_path)
                with open(qa_docs_path, 'rb') as f:
                    qa_documents = pickle.load(f)
                logger.info(f"âœ… RAG Q&A ì¸ë±ìŠ¤ ë¡œë“œ: {len(qa_documents)}ê°œ ë¬¸ì„œ")
            
            # ì˜ë£Œ ë¬¸ì„œ ì¸ë±ìŠ¤ ë° ë¬¸ì„œ ë¡œë“œ
            medical_index = None
            medical_documents = []
            
            medical_index_path = os.path.join(cls.INDEX_DIR, cls.INDEX_FILES["rag_medical"])
            medical_docs_path = os.path.join(cls.INDEX_DIR, cls.METADATA_FILES["rag_medical"])
            
            if os.path.exists(medical_index_path) and os.path.exists(medical_docs_path):
                medical_index = faiss.read_index(medical_index_path)
                with open(medical_docs_path, 'rb') as f:
                    medical_documents = pickle.load(f)
                logger.info(f"âœ… RAG ì˜ë£Œë¬¸ì„œ ì¸ë±ìŠ¤ ë¡œë“œ: {len(medical_documents)}ê°œ ë¬¸ì„œ")
            
            return qa_index, medical_index, qa_documents, medical_documents
            
        except Exception as e:
            logger.error(f"âŒ RAG ì¸ë±ìŠ¤ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None, None, [], []
    
    @classmethod
    def load_disease_indexes(cls) -> Tuple[Optional[faiss.Index], Optional[faiss.Index], List]:
        """ì§ˆë³‘ ì¸ë±ìŠ¤ ë¡œë“œ"""
        try:
            logger.info("ğŸ”„ ì‚¬ì „ ìƒì„±ëœ ì§ˆë³‘ ì¸ë±ìŠ¤ ë¡œë”© ì¤‘...")
            
            disease_key_index = None
            disease_full_index = None
            disease_metadata = []
            
            # ì¸ë±ìŠ¤ íŒŒì¼ ê²½ë¡œ
            key_index_path = os.path.join(cls.INDEX_DIR, cls.INDEX_FILES["disease_key"])
            full_index_path = os.path.join(cls.INDEX_DIR, cls.INDEX_FILES["disease_full"])
            metadata_path = os.path.join(cls.INDEX_DIR, cls.METADATA_FILES["disease"])
            
            # ì¸ë±ìŠ¤ ë¡œë“œ
            if os.path.exists(key_index_path):
                disease_key_index = faiss.read_index(key_index_path)
                logger.info("âœ… ì§ˆë³‘ Key ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ")
            
            if os.path.exists(full_index_path):
                disease_full_index = faiss.read_index(full_index_path)
                logger.info("âœ… ì§ˆë³‘ Full ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ")
            
            # ë©”íƒ€ë°ì´í„° ë¡œë“œ
            if os.path.exists(metadata_path):
                with open(metadata_path, 'rb') as f:
                    disease_metadata = pickle.load(f)
                logger.info(f"âœ… ì§ˆë³‘ ë©”íƒ€ë°ì´í„° ë¡œë“œ: {len(disease_metadata)}ê°œ")
            
            return disease_key_index, disease_full_index, disease_metadata
            
        except Exception as e:
            logger.error(f"âŒ ì§ˆë³‘ ì¸ë±ìŠ¤ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None, None, []
    
    @classmethod
    def load_medication_index(cls) -> Tuple[Optional[faiss.Index], List]:
        """ì˜ì•½í’ˆ ì¸ë±ìŠ¤ ë¡œë“œ"""
        try:
            logger.info("ğŸ”„ ì‚¬ì „ ìƒì„±ëœ ì˜ì•½í’ˆ ì¸ë±ìŠ¤ ë¡œë”© ì¤‘...")
            
            medication_index = None
            medication_metadata = []
            
            # íŒŒì¼ ê²½ë¡œ
            index_path = os.path.join(cls.INDEX_DIR, cls.INDEX_FILES["medication"])
            metadata_path = os.path.join(cls.INDEX_DIR, cls.METADATA_FILES["medication"])
            
            # ì¸ë±ìŠ¤ ë¡œë“œ
            if os.path.exists(index_path):
                medication_index = faiss.read_index(index_path)
                logger.info("âœ… ì˜ì•½í’ˆ ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ")
            
            # ë©”íƒ€ë°ì´í„° ë¡œë“œ
            if os.path.exists(metadata_path):
                with open(metadata_path, 'rb') as f:
                    medication_metadata = pickle.load(f)
                logger.info(f"âœ… ì˜ì•½í’ˆ ë©”íƒ€ë°ì´í„° ë¡œë“œ: {len(medication_metadata)}ê°œ")
            
            return medication_index, medication_metadata
            
        except Exception as e:
            logger.error(f"âŒ ì˜ì•½í’ˆ ì¸ë±ìŠ¤ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None, []
    
    @classmethod
    def get_index_info(cls) -> Dict:
        """ì¸ë±ìŠ¤ ì •ë³´ ë°˜í™˜"""
        config_path = os.path.join(cls.INDEX_DIR, cls.CONFIG_FILE)
        
        if os.path.exists(config_path):
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                logger.error(f"ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        return {}

# =============================================================================
# RAG ê´€ë ¨ í´ë˜ìŠ¤ - ê¸°ì¡´ê³¼ ë™ì¼
# =============================================================================

class RAGContentType(Enum):
    """RAG ì»¨í…ì¸  íƒ€ì…"""
    QA = "qa"                    
    MEDICAL_DOC = "medical_doc"  

@dataclass
class RAGDocument:
    """RAG ë¬¸ì„œ ë°ì´í„° í´ë˜ìŠ¤"""
    doc_id: str
    content: str
    metadata: Dict
    content_type: RAGContentType
    embedding: Optional[np.ndarray] = None

class OptimizedRAGIndexManager:
    """ğŸš€ ìµœì í™”ëœ RAG ì¸ë±ìŠ¤ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, embedding_model):
        self.embedding_model = embedding_model
        self.qa_index = None
        self.medical_doc_index = None
        self.qa_documents = []
        self.medical_documents = []
        self.use_prebuilt = False
        
    def load_rag_data(self):
        """ğŸš€ RAG ë°ì´í„° ë¡œë”© - ì‚¬ì „ ìƒì„±ëœ ì¸ë±ìŠ¤ ìš°ì„  ì‚¬ìš©"""
        start_time = datetime.now()
        
        # 1. ì‚¬ì „ ìƒì„±ëœ ì¸ë±ìŠ¤ ì‚¬ìš© ì‹œë„
        if PreBuiltIndexLoader.check_indexes_available():
            logger.info("ğŸš€ ì‚¬ì „ ìƒì„±ëœ RAG ì¸ë±ìŠ¤ ì‚¬ìš©")
            
            qa_index, medical_index, qa_docs, medical_docs = PreBuiltIndexLoader.load_rag_indexes()
            
            if qa_index and medical_index:
                self.qa_index = qa_index
                self.medical_doc_index = medical_index
                self.qa_documents = qa_docs
                self.medical_documents = medical_docs
                self.use_prebuilt = True
                
                load_time = datetime.now() - start_time
                logger.info(f"âœ… ì‚¬ì „ ìƒì„±ëœ ì¸ë±ìŠ¤ ë¡œë”© ì™„ë£Œ! ì†Œìš”ì‹œê°„: {load_time}")
                logger.info(f"   - Q&A ë¬¸ì„œ: {len(self.qa_documents)}ê°œ")
                logger.info(f"   - ì˜ë£Œ ë¬¸ì„œ: {len(self.medical_documents)}ê°œ")
                return
        
        # 2. ë°±ì—… ëª¨ë“œ: ì‹¤ì‹œê°„ ìƒì„±
        logger.info("ğŸ”„ ë°±ì—… ëª¨ë“œ: RAG ì¸ë±ìŠ¤ ì‹¤ì‹œê°„ ìƒì„±")
        self._load_rag_data_realtime()
        
        load_time = datetime.now() - start_time
        logger.info(f"âš ï¸ ì‹¤ì‹œê°„ ìƒì„± ì™„ë£Œ. ì†Œìš”ì‹œê°„: {load_time}")
        logger.info("ğŸ’¡ ë‹¤ìŒì—ëŠ” generate_faiss_indexes.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ì¸ë±ìŠ¤ë¥¼ ì‚¬ì „ ìƒì„±í•˜ì„¸ìš”!")
        
    def _load_rag_data_realtime(self):
        """ì‹¤ì‹œê°„ RAG ë°ì´í„° ë¡œë”©"""
        logger.info("ğŸ”„ RAG ë°ì´í„° ì‹¤ì‹œê°„ ë¡œë”© ì‹œì‘...")
        
        # Q&A ë°ì´í„° ë¡œë“œ (clean_51004.csv)
        self._load_qa_data()
        
        # ì˜ë£Œ ë¬¸ì„œ ë°ì´í„° ë¡œë“œ (ë‚˜ë¨¸ì§€ 5ê°œ clean_ íŒŒì¼ë“¤)
        self._load_medical_documents()
        
        # ì¸ë±ìŠ¤ êµ¬ì¶•
        self._build_indexes()
        
        logger.info("âœ… RAG ë°ì´í„° ì‹¤ì‹œê°„ ë¡œë”© ì™„ë£Œ!")
        
    def _load_qa_data(self):
        """Q&A ë°ì´í„° ë¡œë“œ"""
        try:
            if not os.path.exists("clean_51004.csv"):
                logger.warning("âš ï¸ clean_51004.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                return
                
            df = pd.read_csv("clean_51004.csv", encoding="utf-8")
            
            for idx, row in df.iterrows():
                try:
                    question = str(row.get('question', ''))
                    answer = str(row.get('answer', ''))
                    
                    if question and answer:
                        content = f"Q: {question}\nA: {answer}"
                        
                        doc = RAGDocument(
                            doc_id=f"qa_{idx}",
                            content=content,
                            metadata={
                                'question': question,
                                'answer': answer,
                                'source': 'clean_51004'
                            },
                            content_type=RAGContentType.QA
                        )
                        self.qa_documents.append(doc)
                        
                except Exception as e:
                    logger.error(f"Q&A ë°ì´í„° ì²˜ë¦¬ ì˜¤ë¥˜ (í–‰ {idx}): {e}")
                    
            logger.info(f"âœ… Q&A ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.qa_documents)}ê°œ")
            
        except Exception as e:
            logger.error(f"âŒ Q&A ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def _load_medical_documents(self):
        """ì˜ë£Œ ë¬¸ì„œ ë°ì´í„° ë¡œë“œ"""
        clean_files = [
            "clean_55588.csv", "clean_56763.csv", "clean_58572.csv", 
            "clean_63166.csv", "clean_66149.csv"
        ]
        
        for file_path in clean_files:
            try:
                if not os.path.exists(file_path):
                    logger.warning(f"âš ï¸ {file_path} íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                    continue
                    
                df = pd.read_csv(file_path, encoding="utf-8")
                
                for idx, row in df.iterrows():
                    try:
                        content_parts = []
                        
                        for col in df.columns:
                            value = str(row.get(col, '')).strip()
                            if value and value != 'nan' and len(value) > 5:
                                content_parts.append(f"{col}: {value}")
                        
                        if content_parts:
                            content = "\n".join(content_parts)
                            
                            doc = RAGDocument(
                                doc_id=f"med_{file_path}_{idx}",
                                content=content,
                                metadata={
                                    'source': file_path,
                                    'original_data': row.to_dict()
                                },
                                content_type=RAGContentType.MEDICAL_DOC
                            )
                            self.medical_documents.append(doc)
                            
                    except Exception as e:
                        logger.error(f"ì˜ë£Œ ë¬¸ì„œ ì²˜ë¦¬ ì˜¤ë¥˜ {file_path} (í–‰ {idx}): {e}")
                        
                logger.info(f"âœ… {file_path} ë¡œë“œ ì™„ë£Œ")
                
            except Exception as e:
                logger.error(f"âŒ {file_path} ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        logger.info(f"âœ… ì˜ë£Œ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ: {len(self.medical_documents)}ê°œ")
    
    def _build_indexes(self):
        """FAISS ì¸ë±ìŠ¤ êµ¬ì¶•"""
        try:
            # Q&A ì¸ë±ìŠ¤ êµ¬ì¶•
            if self.qa_documents:
                qa_texts = [doc.content for doc in self.qa_documents]
                qa_embeddings = self.embedding_model.encode(qa_texts)
                faiss.normalize_L2(qa_embeddings)
                
                self.qa_index = faiss.IndexFlatIP(qa_embeddings.shape[1])
                self.qa_index.add(qa_embeddings)
                logger.info(f"âœ… Q&A ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ: {len(self.qa_documents)}ê°œ")
            
            # ì˜ë£Œ ë¬¸ì„œ ì¸ë±ìŠ¤ êµ¬ì¶•
            if self.medical_documents:
                med_texts = [doc.content for doc in self.medical_documents]
                med_embeddings = self.embedding_model.encode(med_texts)
                faiss.normalize_L2(med_embeddings)
                
                self.medical_doc_index = faiss.IndexFlatIP(med_embeddings.shape[1])
                self.medical_doc_index.add(med_embeddings)
                logger.info(f"âœ… ì˜ë£Œ ë¬¸ì„œ ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ: {len(self.medical_documents)}ê°œ")
                
        except Exception as e:
            logger.error(f"âŒ ì¸ë±ìŠ¤ êµ¬ì¶• ì‹¤íŒ¨: {e}")
    
    def get_relevant_context(self, query: str, top_k: int = 3) -> str:
        """ì¿¼ë¦¬ì— ëŒ€í•œ ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰"""
        contexts = []
        
        # Q&A ê²€ìƒ‰
        qa_results = self.search_qa(query, top_k)
        for doc in qa_results:
            contexts.append(f"[Q&A] {doc.content[:200]}...")
        
        # ì˜ë£Œ ë¬¸ì„œ ê²€ìƒ‰
        med_results = self.search_medical_docs(query, top_k)
        for doc in med_results:
            contexts.append(f"[ì˜ë£Œë¬¸ì„œ] {doc.content[:200]}...")
        
        return "\n".join(contexts[:5])  # ìµœëŒ€ 5ê°œ
    
    def search_qa(self, query: str, top_k: int = 3) -> List[RAGDocument]:
        """Q&A ê²€ìƒ‰"""
        if not self.qa_index or not self.qa_documents:
            return []
        
        try:
            query_embedding = self.embedding_model.encode([query])
            faiss.normalize_L2(query_embedding)
            
            scores, indices = self.qa_index.search(query_embedding, top_k)
            
            results = []
            for idx in indices[0]:
                if 0 <= idx < len(self.qa_documents):
                    results.append(self.qa_documents[idx])
            
            return results
        except Exception as e:
            logger.error(f"Q&A ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    
    def search_medical_docs(self, query: str, top_k: int = 3) -> List[RAGDocument]:
        """ì˜ë£Œ ë¬¸ì„œ ê²€ìƒ‰"""
        if not self.medical_doc_index or not self.medical_documents:
            return []
        
        try:
            query_embedding = self.embedding_model.encode([query])
            faiss.normalize_L2(query_embedding)
            
            scores, indices = self.medical_doc_index.search(query_embedding, top_k)
            
            results = []
            for idx in indices[0]:
                if 0 <= idx < len(self.medical_documents):
                    results.append(self.medical_documents[idx])
            
            return results
        except Exception as e:
            logger.error(f"ì˜ë£Œ ë¬¸ì„œ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []

# =============================================================================
# ì„ë² ë”© ëª¨ë¸ í´ë˜ìŠ¤ - ê¸°ì¡´ê³¼ ë™ì¼
# =============================================================================

class EmbeddingModel:
    """KM-BERT ì„ë² ë”© ëª¨ë¸ í´ë˜ìŠ¤"""
    
    def __init__(self, model_name: str = "madatnlp/km-bert"):
        logger.info(f"ğŸ”„ ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘: {model_name}")
        self.device = "mps" if torch.backends.mps.is_available() else "cpu"
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModel.from_pretrained(model_name).to(self.device)
        self.model.eval()
        logger.info(f"âœ… KM-BERT ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (Device: {self.device})")

    def encode(self, texts: List[str]) -> np.ndarray:
        """í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ì¸ì½”ë”©"""
        encodings = self.tokenizer(
            texts,
            padding=True,
            truncation=True,
            max_length=128,
            return_tensors="pt"
        ).to(self.device)

        with torch.no_grad():
            outputs = self.model(**encodings)
            last_hidden = outputs.last_hidden_state
            attention_mask = encodings.attention_mask.unsqueeze(-1)
            masked_hidden = last_hidden * attention_mask
            sum_hidden = masked_hidden.sum(dim=1)
            lengths = attention_mask.sum(dim=1)
            sentence_embeddings = sum_hidden / lengths.clamp(min=1e-9)
            return sentence_embeddings.cpu().numpy()

# =============================================================================
# EXAONE LLM í´ë˜ìŠ¤ - ê¸°ì¡´ê³¼ ë™ì¼
# =============================================================================

class EXAONE:
    """EXAONE LLM ì„œë¹„ìŠ¤ í´ë˜ìŠ¤"""
    
    def __init__(self, model_name: str = "exaone3.5:7.8b"):
        self.model_name = model_name
        self.base_url = "http://localhost:11434"
        self.endpoint = None
        
        self.exaone_config = {
            "temperature": 0.3,
            "top_p": 0.8,
            "max_tokens": 2048,
            "repeat_penalty": 1.1
        }
        
        logger.info(f"ğŸ”§ EXAONE ì´ˆê¸°í™”: {model_name}")
        
        if self._check_endpoint("chat"):
            self.endpoint = "chat"
            logger.info("âœ… EXAONE chat ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©")
        elif self._check_endpoint("generate"):
            self.endpoint = "generate"
            logger.info("âœ… EXAONE generate ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©")
        else:
            logger.warning("âš ï¸ EXAONE ì„œë²„ ì—°ê²° ì‹¤íŒ¨. ê¸°ë³¸ ì‘ë‹µ ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")

    def _check_endpoint(self, endpoint: str) -> bool:
        """ì—”ë“œí¬ì¸íŠ¸ ì—°ê²° í™•ì¸"""
        try:
            response = requests.get(f"{self.base_url}/api/tags", timeout=5)
            return response.status_code == 200
        except:
            return False

    def generate_response(self, prompt: str, system_prompt: str = "") -> str:
        """EXAONE ëª¨ë¸ ì‘ë‹µ ìƒì„±"""
        if not self.endpoint:
            return "âš ï¸ EXAONE ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Ollamaê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”."
        
        try:
            if self.endpoint == "chat":
                return self._chat_request(prompt, system_prompt)
            else:
                return self._generate_request(prompt, system_prompt)
        except Exception as e:
            logger.error(f"EXAONE ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")
            return f"âš ï¸ EXAONE ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

    def _chat_request(self, prompt: str, system_prompt: str) -> str:
        """Chat API ìš”ì²­"""
        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        messages.append({"role": "user", "content": prompt})
        
        response = requests.post(
            f"{self.base_url}/api/chat",
            json={
                "model": self.model_name,
                "messages": messages,
                "stream": False,
                **self.exaone_config
            },
            timeout=30
        )
        
        if response.status_code == 200:
            return response.json()["message"]["content"]
        else:
            return f"âš ï¸ API ìš”ì²­ ì‹¤íŒ¨: {response.status_code}"

    def _generate_request(self, prompt: str, system_prompt: str) -> str:
        """Generate API ìš”ì²­"""
        full_prompt = f"{system_prompt}\n\n{prompt}" if system_prompt else prompt
        
        response = requests.post(
            f"{self.base_url}/api/generate",
            json={
                "model": self.model_name,
                "prompt": full_prompt,
                "stream": False,
                **self.exaone_config
            },
            timeout=30
        )
        
        if response.status_code == 200:
            return response.json()["response"]
        else:
            return f"âš ï¸ API ìš”ì²­ ì‹¤íŒ¨: {response.status_code}"

# =============================================================================
# ê¸°íƒ€ ë¡œë”© í•¨ìˆ˜ë“¤ - ê¸°ì¡´ê³¼ ë™ì¼
# =============================================================================

def detect_columns(df: pd.DataFrame, data_type: str) -> Dict[str, str]:
    """ë°ì´í„° íƒ€ì…ë³„ ì»¬ëŸ¼ ê°ì§€"""
    columns = df.columns.tolist()
    detected = {}
    
    if data_type == "disease":
        column_mappings = {
            'disease_name': ['disnm_ko', 'disnm_en', 'disease', 'ì§ˆë³‘', 'ë³‘ëª…', 'disease_name'],
            'symptoms': ['sym', 'symptoms', 'ì¦ìƒ', 'symptom'],
            'symptoms_key': ['sym_k', 'symptoms_key', 'í•µì‹¬ì¦ìƒ', 'key_symptoms']
        }
        
        for target_type, possible_names in column_mappings.items():
            for col in columns:
                if col in possible_names:
                    detected[target_type] = col
                    break
                col_lower = col.lower()
                for possible in possible_names:
                    if possible.lower() in col_lower or col_lower in possible.lower():
                        detected[target_type] = col
                        break
                if target_type in detected:
                    break
    
    elif data_type == "medication":
        for col in columns:
            col_lower = col.lower()
            if any(keyword in col_lower for keyword in ['item', 'í’ˆëª©', 'ì•½í’ˆëª…']):
                detected['itemName'] = col
            elif any(keyword in col_lower for keyword in ['efcy', 'íš¨ëŠ¥', 'íš¨ê³¼']):
                detected['efcyQesitm'] = col
    
    return detected

def discover_csv_files() -> Tuple[List[str], List[str]]:
    """CSV íŒŒì¼ ìë™ íƒì§€"""
    files = [f for f in os.listdir('.') if f.lower().endswith(".csv")]
    
    disease_files = []
    medication_files = []

    for fname in files:
        try:
            df = pd.read_csv(fname, encoding="utf-8", low_memory=False, nrows=5)
        except Exception:
            continue

        d_cols = detect_columns(df, "disease")
        if "disease_name" in d_cols and (d_cols.get("symptoms") or d_cols.get("symptoms_key")):
            disease_files.append(fname)
            logger.info(f"ğŸ¥ ì§ˆë³‘ íŒŒì¼ ë°œê²¬: {fname} (ì»¬ëŸ¼: {d_cols})")
            continue

        m_cols = detect_columns(df, "medication")
        if "itemName" in m_cols and "efcyQesitm" in m_cols:
            medication_files.append(fname)
            logger.info(f"ğŸ’Š ì˜ì•½í’ˆ íŒŒì¼ ë°œê²¬: {fname} (ì»¬ëŸ¼: {m_cols})")
            continue

    return disease_files, medication_files

def optimized_load_disease_indexes(
    csv_paths: List[str],
    embedding_model: EmbeddingModel
) -> Tuple[faiss.IndexFlatIP, faiss.IndexFlatIP, List[Dict]]:
    """ğŸš€ ìµœì í™”ëœ ì§ˆë³‘ ë°ì´í„° ë¡œë“œ"""
    
    # 1. ì‚¬ì „ ìƒì„±ëœ ì¸ë±ìŠ¤ ì‚¬ìš© ì‹œë„
    if PreBuiltIndexLoader.check_indexes_available():
        logger.info("ğŸš€ ì‚¬ì „ ìƒì„±ëœ ì§ˆë³‘ ì¸ë±ìŠ¤ ì‚¬ìš©")
        
        disease_key_index, disease_full_index, disease_metadata = PreBuiltIndexLoader.load_disease_indexes()
        
        if disease_key_index and disease_full_index and disease_metadata:
            logger.info(f"âœ… ì§ˆë³‘ ì¸ë±ìŠ¤ ë¡œë”© ì™„ë£Œ: {len(disease_metadata)}ê°œ")
            return disease_key_index, disease_full_index, disease_metadata
    
    # 2. ë°±ì—… ëª¨ë“œ: ì‹¤ì‹œê°„ ìƒì„±
    logger.info("ğŸ”„ ë°±ì—… ëª¨ë“œ: ì§ˆë³‘ ì¸ë±ìŠ¤ ì‹¤ì‹œê°„ ìƒì„±")
    return load_and_build_disease_indexes(csv_paths, embedding_model)

def optimized_load_medication_index(
    csv_paths: List[str],
    embedding_model: EmbeddingModel
) -> Tuple[faiss.IndexFlatIP, List[Dict]]:
    """ğŸš€ ìµœì í™”ëœ ì˜ì•½í’ˆ ë°ì´í„° ë¡œë“œ"""
    
    # 1. ì‚¬ì „ ìƒì„±ëœ ì¸ë±ìŠ¤ ì‚¬ìš© ì‹œë„
    if PreBuiltIndexLoader.check_indexes_available():
        logger.info("ğŸš€ ì‚¬ì „ ìƒì„±ëœ ì˜ì•½í’ˆ ì¸ë±ìŠ¤ ì‚¬ìš©")
        
        medication_index, medication_metadata = PreBuiltIndexLoader.load_medication_index()
        
        if medication_index and medication_metadata:
            logger.info(f"âœ… ì˜ì•½í’ˆ ì¸ë±ìŠ¤ ë¡œë”© ì™„ë£Œ: {len(medication_metadata)}ê°œ")
            return medication_index, medication_metadata
    
    # 2. ë°±ì—… ëª¨ë“œ: ì‹¤ì‹œê°„ ìƒì„±
    logger.info("ğŸ”„ ë°±ì—… ëª¨ë“œ: ì˜ì•½í’ˆ ì¸ë±ìŠ¤ ì‹¤ì‹œê°„ ìƒì„±")
    return load_and_build_medication_index(csv_paths, embedding_model)

def load_and_build_disease_indexes(
    csv_paths: List[str],
    embedding_model: EmbeddingModel
) -> Tuple[faiss.IndexFlatIP, faiss.IndexFlatIP, List[Dict]]:
    """ì§ˆë³‘ ë°ì´í„° ë¡œë“œ ë° FAISS ì¸ë±ìŠ¤ êµ¬ì¶•"""
    
    all_key_embs = []
    all_full_embs = []
    all_docs_meta = []

    for path in csv_paths:
        logger.info(f"ğŸ“‚ ì§ˆë³‘ ë°ì´í„° ë¡œë“œ ì¤‘: {path}")
        
        try:
            df = pd.read_csv(path, encoding="utf-8", low_memory=False)
            logger.info(f"ğŸ” {path} ì»¬ëŸ¼ í™•ì¸: {list(df.columns)}")
            
            detected = detect_columns(df, "disease")
            logger.info(f"ğŸ” ê°ì§€ëœ ì§ˆë³‘ ì»¬ëŸ¼: {detected}")
            
            disease_col = detected.get("disease_name")
            symptoms_col = detected.get("symptoms")
            symptoms_key_col = detected.get("symptoms_key")
            
            if not disease_col:
                logger.warning(f"âš ï¸ {path}: ì§ˆë³‘ëª… ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                continue
            
            valid_rows = 0
            for _, row in df.iterrows():
                try:
                    disease_name = str(row.get(disease_col, "")).strip()
                    if not disease_name or disease_name == "nan":
                        continue
                    
                    # ì¦ìƒ ì •ë³´ ìˆ˜ì§‘
                    symptoms_full = ""
                    symptoms_key = ""
                    
                    if symptoms_col:
                        symptoms_full = str(row.get(symptoms_col, "")).strip()
                    if symptoms_key_col:
                        symptoms_key = str(row.get(symptoms_key_col, "")).strip()
                    
                    # ê¸°íƒ€ ì»¬ëŸ¼ë“¤ë„ ìˆ˜ì§‘
                    additional_info = []
                    for col in ['def', 'therapy', 'diag', 'guide', 'pvt']:
                        if col in df.columns:
                            value = str(row.get(col, "")).strip()
                            if value and value != "nan":
                                additional_info.append(value)
                    
                    # ë©”íƒ€ë°ì´í„° êµ¬ì„±
                    doc_meta = {
                        "disease": disease_name,
                        "symptoms": symptoms_full,
                        "symptoms_key": symptoms_key,
                        "additional_info": " ".join(additional_info),
                        "source_file": path,
                        "original_data": row.to_dict()
                    }
                    
                    # ì„ë² ë”©ìš© í…ìŠ¤íŠ¸ êµ¬ì„±
                    key_text = f"{disease_name} {symptoms_key}".strip()
                    full_text = f"{disease_name} {symptoms_full} {symptoms_key} {' '.join(additional_info)}".strip()
                    
                    all_docs_meta.append(doc_meta)
                    all_key_embs.append(key_text)
                    all_full_embs.append(full_text)
                    valid_rows += 1
                    
                except Exception as e:
                    logger.error(f"í–‰ ì²˜ë¦¬ ì˜¤ë¥˜ {path}: {e}")
                    continue
            
            logger.info(f"âœ… {path}: {valid_rows}ê°œ ì§ˆë³‘ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ {path} ë¡œë“œ ì‹¤íŒ¨: {e}")
            continue

    if not all_docs_meta:
        raise ValueError("ìœ íš¨í•œ ì§ˆë³‘ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    logger.info(f"ğŸ”„ ì§ˆë³‘ ì„ë² ë”© ìƒì„± ì¤‘: {len(all_docs_meta)}ê±´")

    # ì„ë² ë”© ìƒì„±
    key_embeddings = embedding_model.encode(all_key_embs)
    full_embeddings = embedding_model.encode(all_full_embs)

    # FAISS ì¸ë±ìŠ¤ êµ¬ì¶•  
    faiss.normalize_L2(key_embeddings)
    faiss.normalize_L2(full_embeddings)
    
    index_key = faiss.IndexFlatIP(key_embeddings.shape[1])
    index_full = faiss.IndexFlatIP(full_embeddings.shape[1])
    
    index_key.add(key_embeddings)
    index_full.add(full_embeddings)

    logger.info(f"âœ… ì§ˆë³‘ FAISS ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ: {len(all_docs_meta)}ê±´")
    return index_key, index_full, all_docs_meta

def load_and_build_medication_index(
    csv_paths: List[str],
    embedding_model: EmbeddingModel
) -> Tuple[faiss.IndexFlatIP, List[Dict]]:
    """ì˜ì•½í’ˆ ë°ì´í„° ë¡œë“œ ë° FAISS ì¸ë±ìŠ¤ êµ¬ì¶•"""
    
    all_med_docs = []
    all_med_meta = []

    for path in csv_paths:
        logger.info(f"ğŸ“‚ ì˜ì•½í’ˆ ë°ì´í„° ë¡œë“œ ì¤‘: {path}")
        
        try:
            df = pd.read_csv(path, encoding="utf-8", low_memory=False)
            detected = detect_columns(df, "medication")
            
            item_col = detected.get("itemName")
            efcy_col = detected.get("efcyQesitm")
            
            if not item_col or not efcy_col:
                logger.warning(f"âš ï¸ {path}: í•„ìš”í•œ ì˜ì•½í’ˆ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                continue
            
            valid_rows = 0
            for _, row in df.iterrows():
                try:
                    item_name = str(row.get(item_col, "")).strip()
                    efficacy = str(row.get(efcy_col, "")).strip()
                    
                    if not item_name or not efficacy or item_name == "nan" or efficacy == "nan":
                        continue
                    
                    # ë¬¸ì„œ í…ìŠ¤íŠ¸ êµ¬ì„±
                    doc_text = f"ì˜ì•½í’ˆëª…: {item_name}\níš¨ëŠ¥: {efficacy}"
                    
                    # ë©”íƒ€ë°ì´í„° êµ¬ì„±
                    doc_meta = {
                        "name": item_name,
                        "efficacy": efficacy,
                        "doc_text": doc_text,
                        "source_file": path,
                        "original_data": row.to_dict()
                    }
                    
                    all_med_docs.append(doc_text)
                    all_med_meta.append(doc_meta)
                    valid_rows += 1
                    
                except Exception as e:
                    logger.error(f"ì˜ì•½í’ˆ í–‰ ì²˜ë¦¬ ì˜¤ë¥˜ {path}: {e}")
                    continue
            
            logger.info(f"âœ… {path}: {valid_rows}ê°œ ì˜ì•½í’ˆ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ {path} ë¡œë“œ ì‹¤íŒ¨: {e}")
            continue

    if not all_med_docs:
        logger.warning("âš ï¸ ìœ íš¨í•œ ì˜ì•½í’ˆ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None, []

    logger.info(f"ğŸ”„ ì˜ì•½í’ˆ ì„ë² ë”© ìƒì„± ì¤‘: {len(all_med_docs)}ê±´")

    # ì„ë² ë”© ìƒì„±
    med_embeddings = embedding_model.encode(all_med_docs)

    # FAISS ì¸ë±ìŠ¤ êµ¬ì¶•  
    faiss.normalize_L2(med_embeddings)
    med_index = faiss.IndexFlatIP(med_embeddings.shape[1])
    med_index.add(med_embeddings)

    logger.info(f"âœ… ì˜ì•½í’ˆ FAISS ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ: {len(all_med_docs)}ê±´")
    return med_index, all_med_meta

# =============================================================================
# ì„¸ì…˜ ê´€ë¦¬ í´ë˜ìŠ¤ - ê¸°ì¡´ê³¼ ë™ì¼
# =============================================================================

class IntegratedSession:
    """ğŸ”¥ ì™„ì „í•œ í†µí•© ì„¸ì…˜ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.session_id = f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.history = []
        self.context = {
            "last_intent": None,
            "last_entity": None, 
            "last_disease": None,
            "last_final_diagnosis": None,
            "diagnosed_diseases": [],
            "detected_symptoms": [],
            "diagnosis_time": None,
            "disease_symptoms_mapping": {},
            "last_medications": [],
            "recommended_medications": [],
            "medication_queries": [],
            "user_medication_profile": {
                "age_group": None,
                "is_pregnant": None,
                "chronic_conditions": []
            },
            # ğŸ”¥ ìˆ˜ì •ëœ ì°¨ë³„í™” ì§ˆë¬¸ ìƒíƒœ
            "questioning_state": {
                "is_questioning": False,
                "current_candidates": [],
                "asked_questions": [],
                "user_answers": {},
                "current_question_index": 0,
                "max_questions": 3
            },
            # ğŸ”¥ ìƒˆë¡œ ì¶”ê°€ëœ í•„ë“œë“¤
            "initial_symptoms_text": "",  # ì´ˆê¸° ì¦ìƒ í…ìŠ¤íŠ¸ ì €ì¥
            "mentioned_symptoms": []       # ì‚¬ìš©ìê°€ ì–¸ê¸‰í•œ ì¦ìƒë“¤
        }
    
    def reset_session(self):
        """ì„¸ì…˜ ì´ˆê¸°í™”"""
        old_session_id = self.session_id
        self.__init__()
        logger.info(f"ğŸ”„ ì„¸ì…˜ ì´ˆê¸°í™”: {old_session_id} â†’ {self.session_id}")
    
    def add_message(self, user_message: str, bot_response: str, intent: str):
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ë©”ì‹œì§€ ì¶”ê°€"""
        self.history.append({
            "timestamp": datetime.now(),
            "user_message": user_message,
            "bot_response": bot_response,
            "intent": intent
        })
        
        if len(self.history) > 50:
            self.history = self.history[-50:]
    
    def get_recent_diagnosis(self) -> Optional[str]:
        """ìµœê·¼ ì§„ë‹¨ëœ ì§ˆë³‘ ë°˜í™˜ (30ë¶„ ì´ë‚´)"""
        if not self.context["last_final_diagnosis"] or not self.context["diagnosis_time"]:
            return None
        
        time_diff = datetime.now() - self.context["diagnosis_time"]
        if time_diff > timedelta(minutes=30):
            return None
        
        return self.context["last_final_diagnosis"]
    
    def update_disease_context(self, disease: str, symptoms: List[str], intent: str):
        """ì§ˆë³‘ ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸"""
        self.context["last_disease"] = disease
        self.context["last_intent"] = intent
        self.context["diagnosis_time"] = datetime.now()
        
        if disease:
            self.context["diagnosed_diseases"].append({
                "disease": disease,
                "symptoms": symptoms,
                "timestamp": datetime.now()
            })
        
        if symptoms:
            self.context["detected_symptoms"].extend(symptoms)
            self.context["disease_symptoms_mapping"][disease] = symptoms
    
    def get_disease_symptoms(self, disease: str) -> List[str]:
        """íŠ¹ì • ì§ˆë³‘ì˜ ì¦ìƒ ëª©ë¡ ë°˜í™˜"""
        return self.context["disease_symptoms_mapping"].get(disease, [])
    
    def update_medication_context(self, medications: List[Dict]):
        """ì˜ì•½í’ˆ ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸"""
        self.context["last_medications"] = medications
        self.context["recommended_medications"].extend(medications)
        
        if len(self.context["recommended_medications"]) > 10:
            self.context["recommended_medications"] = self.context["recommended_medications"][-10:]
    
    def start_questioning(self, candidates: List[Dict], questions: List[str]):
        """ì°¨ë³„í™” ì§ˆë¬¸ ëª¨ë“œ ì‹œì‘"""
        state = self.context["questioning_state"]
        state["is_questioning"] = True
        state["current_candidates"] = candidates
        state["asked_questions"] = questions
        state["user_answers"] = {}
        state["current_question_index"] = 0
        logger.info(f"ğŸ”¬ ì°¨ë³„í™” ì§ˆë¬¸ ëª¨ë“œ ì‹œì‘: {len(candidates)}ê°œ í›„ë³´, {len(questions)}ê°œ ì§ˆë¬¸")
    
    def get_current_question(self) -> Optional[str]:
        """í˜„ì¬ ì§ˆë¬¸ ë°˜í™˜"""
        state = self.context["questioning_state"]
        if (state["is_questioning"] and 
            state["current_question_index"] < len(state["asked_questions"])):
            return state["asked_questions"][state["current_question_index"]]
        return None
    
    def add_answer(self, question: str, answer: str):
        """ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ì¶”ê°€"""
        self.context["questioning_state"]["user_answers"][question] = answer
    
    def next_question(self):
        """ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ ì´ë™"""
        self.context["questioning_state"]["current_question_index"] += 1
    
    def should_continue_questioning(self) -> bool:
        """ì§ˆë¬¸ì„ ê³„ì†í•´ì•¼ í•˜ëŠ”ì§€ íŒë‹¨"""
        state = self.context["questioning_state"]
        return (state["is_questioning"] and 
                state["current_question_index"] < len(state["asked_questions"]) and
                state["current_question_index"] < state["max_questions"])
    
    def finish_questioning(self):
        """ì§ˆë¬¸ ëª¨ë“œ ì¢…ë£Œ"""
        self.context["questioning_state"]["is_questioning"] = False
        logger.info("ğŸ”¬ ì°¨ë³„í™” ì§ˆë¬¸ ëª¨ë“œ ì¢…ë£Œ")

# =============================================================================
# ğŸ”¥ ìˆ˜ì •ëœ ê°•í™”ëœ ì§ˆë³‘ ì„œë¹„ìŠ¤ í´ë˜ìŠ¤
# =============================================================================

class EnhancedDiseaseService:
    """ğŸ”¥ ìˆ˜ì •ëœ ê°•í™”ëœ ì§ˆë³‘ ì„œë¹„ìŠ¤ - ìŠ¤ë§ˆíŠ¸í•œ ì°¨ë³„í™” ì§ˆë¬¸"""
    
    def __init__(self, exaone_service, disease_index_key, disease_index_full, 
                 disease_meta, embedding_model, rag_manager):
        self.exaone = exaone_service
        self.disease_index_key = disease_index_key
        self.disease_index_full = disease_index_full
        self.disease_meta = disease_meta
        self.embedding_model = embedding_model
        self.rag_manager = rag_manager
        
        # ğŸ”¥ ì¦ìƒ í‚¤ì›Œë“œ ë§¤í•‘ (ê°œì„ )
        self.symptom_keywords = {
            "ë°œì—´": ["ì—´", "ë°œì—´", "ì²´ì˜¨", "ëœ¨ê±°ì›Œ", "í›„ëˆ", "ë¯¸ì—´", "ê³ ì—´"],
            "ë‘í†µ": ["ë¨¸ë¦¬", "ë‘í†µ", "ë¨¸ë¦¬ì•„", "ì •ìˆ˜ë¦¬", "ê´€ìë†€ì´", "ë¨¸ë¦¬ê°€ì•„"],
            "ê¸°ì¹¨": ["ê¸°ì¹¨", "ì¼ì¼", "ì»´ì»´", "ë§ˆë¥¸ê¸°ì¹¨", "ê°€ë˜ê¸°ì¹¨"],
            "ì½§ë¬¼": ["ì½§ë¬¼", "ì½”ë§‰í˜", "ì½”ê°€ë§‰", "ì¬ì±„ê¸°", "ì½”ê°ê¸°"],
            "ì¸í›„í†µ": ["ëª©ì•„", "ëª©ì´ì•„", "ì¸í›„í†µ", "ëª©ë”°ê°€", "ì‚¼í‚¤ê¸°", "ëª©ì´ë”°"],
            "ê·¼ìœ¡í†µ": ["ëª¸ì‚´", "ê·¼ìœ¡í†µ", "ì˜¨ëª¸", "ì•„í”„ë‹¤", "ì‘¤ì‹œ", "ê²°ë¦¼"],
            "í”¼ë¡œ": ["í”¼ë¡œ", "ë¬´ê¸°ë ¥", "ê¸°ìš´ì—†", "ì¡¸ë ¤", "í˜ë“¤ì–´"]
        }
        
        # ğŸ”¥ ê°ê¸°/ì½”ë¡œë‚˜ ìš°ì„  ì§„ë‹¨ì„ ìœ„í•œ ì¦ìƒ ê°€ì¤‘ì¹˜
        self.symptom_weights = {
            "ê¸°ì¹¨": 0.3, "ì½§ë¬¼": 0.25, "ì¸í›„í†µ": 0.25, "ë°œì—´": 0.35,
            "ë‘í†µ": 0.2, "ê·¼ìœ¡í†µ": 0.2, "í”¼ë¡œ": 0.15
        }
        
    def extract_mentioned_symptoms(self, symptoms_text: str) -> Set[str]:
        """ğŸ”¥ ìƒˆë¡œ ì¶”ê°€: ì‚¬ìš©ìê°€ ì´ë¯¸ ì–¸ê¸‰í•œ ì¦ìƒë“¤ ì¶”ì¶œ"""
        symptoms_lower = symptoms_text.lower()
        mentioned_symptoms = set()
        
        for symptom_type, keywords in self.symptom_keywords.items():
            for keyword in keywords:
                if keyword in symptoms_lower:
                    mentioned_symptoms.add(symptom_type)
                    break
        
        logger.info(f"ğŸ” ê°ì§€ëœ ê¸°ì¡´ ì¦ìƒ: {mentioned_symptoms}")
        return mentioned_symptoms
        
    def diagnose_disease(self, symptoms_text: str, session: IntegratedSession) -> str:
        """ğŸ”¥ ìˆ˜ì •ëœ ì§ˆë³‘ ì§„ë‹¨ - ê°œì„ ëœ ì°¨ë³„í™” ì§ˆë¬¸"""
        
        # ğŸ”¥ ì´ˆê¸° ì¦ìƒì„ ì„¸ì…˜ì— ì €ì¥ (ì¤‘ìš”!)
        session.context["initial_symptoms_text"] = symptoms_text
        session.context["mentioned_symptoms"] = list(self.extract_mentioned_symptoms(symptoms_text))
        
        # 1. ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ìœ ì‚¬ ì§ˆë³‘ ì°¾ê¸°
        similar_diseases = self._search_similar_diseases(symptoms_text, top_k=8)
        
        # 2. ì¦ìƒ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ê³„ì‚° ë° ì¬ì •ë ¬
        weighted_diseases = self._apply_symptom_weights(symptoms_text, similar_diseases)
        
        # 3. ê°ê¸°/ì½”ë¡œë‚˜ ìš°ì„  ì§„ë‹¨ ë¡œì§
        prioritized_diseases = self._prioritize_common_diseases(symptoms_text, weighted_diseases)
        
        # 4. ì°¨ë³„í™” ì§ˆë¬¸ í•„ìš”ì„± íŒë‹¨ (ì¡°ê±´ ì™„í™”)
        if len(prioritized_diseases) > 1 and prioritized_diseases[0].get('confidence', 0) < 0.85:
            # ğŸ”¥ ìŠ¤ë§ˆíŠ¸í•œ ì§ˆë¬¸ ìƒì„± (ì´ë¯¸ ì•Œê³  ìˆëŠ” ì¦ìƒ ì œì™¸)
            questions = self._generate_smart_differential_questions(symptoms_text, prioritized_diseases)
            if questions:
                session.start_questioning(prioritized_diseases, questions)
                first_question = session.get_current_question()
                
                return f"""ğŸ” **ì´ˆê¸° ë¶„ì„ ê²°ê³¼**:
ì¦ìƒì„ ë¶„ì„í•œ ê²°ê³¼, {len(prioritized_diseases)}ê°€ì§€ ì§ˆë³‘ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤:
{self._format_disease_list(prioritized_diseases[:3])}

ğŸ“š **ê´€ë ¨ ì˜ë£Œ ì •ë³´**:
{self._get_rag_context(symptoms_text)}

ğŸ”¬ **ì •í™•í•œ ì§„ë‹¨ì„ ìœ„í•œ ì¶”ê°€ ì§ˆë¬¸**:
{first_question}

ğŸ’¡ ìœ„ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì‹œë©´ ë” ì •í™•í•œ ì§„ë‹¨ì„ ë„ì™€ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."""
        
        # 5. ìµœì¢… ì§„ë‹¨ ìƒì„± (ì°¨ë³„í™” ì§ˆë¬¸ ì—†ì´ ë°”ë¡œ ì§„ë‹¨)
        return self._generate_enhanced_final_diagnosis(prioritized_diseases[:3], symptoms_text, session)
    
    def _generate_smart_differential_questions(self, symptoms_text: str, diseases: List[Dict]) -> List[str]:
        """ğŸ”¥ ìŠ¤ë§ˆíŠ¸í•œ ì°¨ë³„í™” ì§ˆë¬¸ ìƒì„± - ì´ë¯¸ ì•Œê³  ìˆëŠ” ì¦ìƒì€ ì œì™¸"""
        mentioned_symptoms = self.extract_mentioned_symptoms(symptoms_text)
        
        # ê°€ëŠ¥í•œ ëª¨ë“  ì§ˆë¬¸ë“¤
        all_questions = [
            ("ë°œì—´", "í˜„ì¬ ë°œì—´(ì—´)ì´ ìˆìœ¼ì‹ ê°€ìš”?"),
            ("ê¸°ì¹¨", "ê¸°ì¹¨ì´ë‚˜ ê°€ë˜ ì¦ìƒì´ ìˆìœ¼ì‹ ê°€ìš”?"),
            ("ì¸í›„í†µ", "ëª©ì˜ í†µì¦ì´ë‚˜ ë”°ê°€ì›€ì´ ìˆìœ¼ì‹ ê°€ìš”?"),
            ("ê·¼ìœ¡í†µ", "ê·¼ìœ¡í†µì´ë‚˜ ëª¸ì‚´ ê¸°ìš´ì´ ìˆìœ¼ì‹ ê°€ìš”?"),
            ("ì½§ë¬¼", "ì½”ë§‰í˜ì´ë‚˜ ì½§ë¬¼ ì¦ìƒì´ ìˆìœ¼ì‹ ê°€ìš”?"),
            ("ë‘í†µ", "ë‘í†µì´ë‚˜ ë¨¸ë¦¬ ì•„í”ˆ ì¦ìƒì´ ìˆìœ¼ì‹ ê°€ìš”?"),
            ("í”¼ë¡œ", "í”¼ë¡œê°ì´ë‚˜ ë¬´ê¸°ë ¥í•¨ì„ ëŠë¼ì‹œë‚˜ìš”?")
        ]
        
        # ğŸ”¥ ì´ë¯¸ ì–¸ê¸‰í•œ ì¦ìƒì€ ì§ˆë¬¸ì—ì„œ ì œì™¸
        smart_questions = []
        for symptom_type, question in all_questions:
            if symptom_type not in mentioned_symptoms:
                smart_questions.append(question)
        
        # ìµœëŒ€ 3ê°œ ì§ˆë¬¸ë§Œ ì„ íƒ
        selected_questions = smart_questions[:3]
        
        logger.info(f"ğŸ”¥ ìŠ¤ë§ˆíŠ¸ ì§ˆë¬¸ ìƒì„±: ê¸°ì¡´ ì¦ìƒ {mentioned_symptoms} ì œì™¸, {len(selected_questions)}ê°œ ì§ˆë¬¸ ìƒì„±")
        return selected_questions
    
    def process_followup_answer(self, answer: str, session: IntegratedSession) -> str:
        """ğŸ”¥ ê°œì„ ëœ í›„ì† ë‹µë³€ ì²˜ë¦¬"""
        current_question = session.get_current_question()
        if not current_question:
            return "ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        
        # ë‹µë³€ ê¸°ë¡
        session.add_answer(current_question, answer)
        
        # ğŸ”¥ ê°œì„ ëœ í›„ë³´ í•„í„°ë§
        state = session.context["questioning_state"]
        filtered_candidates = self._improved_filter_candidates(
            state["current_candidates"], current_question, answer, session
        )
        
        # ğŸ”¥ ë¹ˆ ê²°ê³¼ ë°©ì§€ - í•„í„°ë§ì´ ë„ˆë¬´ ê°•í•˜ë©´ ì›ë˜ í›„ë³´ ìœ ì§€
        if len(filtered_candidates) == 0:
            logger.warning("âš ï¸ í•„í„°ë§ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŒ - ì›ë˜ í›„ë³´ ìœ ì§€")
            filtered_candidates = state["current_candidates"]
        
        state["current_candidates"] = filtered_candidates
        
        # ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ ì´ë™
        session.next_question()
        
        # ğŸ”¥ ì¢…ë£Œ ì¡°ê±´ ê°œì„ 
        should_finish = (
            not session.should_continue_questioning() or 
            len(filtered_candidates) <= 1 or
            (len(filtered_candidates) <= 2 and state["current_question_index"] >= 2)
        )
        
        if should_finish:
            session.finish_questioning()
            # ğŸ”¥ ì´ˆê¸° ì¦ìƒ ì •ë³´ë¥¼ í•¨ê»˜ ì „ë‹¬
            initial_symptoms = session.context.get("initial_symptoms_text", "")
            return self._generate_enhanced_final_diagnosis(filtered_candidates, initial_symptoms, session)
        
        # ë‹¤ìŒ ì§ˆë¬¸ ê³„ì†
        next_question = session.get_current_question()
        return f"âœ… ë‹µë³€ ê°ì‚¬í•©ë‹ˆë‹¤.\n\nâ“ {next_question}"
    
    def _improved_filter_candidates(self, candidates: List[Dict], question: str, answer: str, session: IntegratedSession) -> List[Dict]:
        """ğŸ”¥ ê°œì„ ëœ í›„ë³´ í•„í„°ë§ ë¡œì§"""
        answer_lower = answer.lower()
        is_positive = any(word in answer_lower for word in ["ì˜ˆ", "ìˆ", "ë„¤", "ë§", "ê·¸ë˜", "ì‹¬í•´", "ë§ì´"])
        is_negative = any(word in answer_lower for word in ["ì•„ë‹ˆ", "ì—†", "ì•ˆ", "ì•„ì§", "ë³„ë¡œ"])
        
        # ğŸ”¥ ì§ˆë¬¸ ìœ í˜•ë³„ ì •êµí•œ í•„í„°ë§
        if "ë°œì—´" in question or "ì—´" in question:
            if is_positive:
                # ë°œì—´ì´ ìˆìœ¼ë©´ ê°ê¸°/ë…ê°/ì½”ë¡œë‚˜ ê´€ë ¨ ì§ˆë³‘ ìš°ì„ 
                fever_diseases = []
                other_diseases = []
                
                for candidate in candidates:
                    disease_name = candidate.get('disease', '').lower()
                    symptoms = candidate.get('symptoms', '').lower()
                    
                    if any(keyword in disease_name or keyword in symptoms 
                          for keyword in ['ê°ê¸°', 'ë…ê°', 'ì¸í”Œë£¨ì—”ì', 'ìƒê¸°ë„', 'ë°œì—´', 'ì—´']):
                        candidate['confidence'] = candidate.get('confidence', 0) + 0.2
                        fever_diseases.append(candidate)
                    else:
                        other_diseases.append(candidate)
                
                return fever_diseases + other_diseases
        
        elif "ê¸°ì¹¨" in question:
            if is_positive:
                # ê¸°ì¹¨ì´ ìˆìœ¼ë©´ í˜¸í¡ê¸° ì§ˆí™˜ ìš°ì„ 
                cough_diseases = [c for c in candidates 
                                if any(keyword in c.get('disease', '').lower() or keyword in c.get('symptoms', '').lower()
                                      for keyword in ['ê¸°ì¹¨', 'í˜¸í¡', 'í', 'ê¸°ê´€ì§€', 'ì²œì‹'])]
                other_diseases = [c for c in candidates if c not in cough_diseases]
                return cough_diseases + other_diseases
        
        elif "ëª©" in question or "ì¸í›„í†µ" in question:
            if is_positive:
                # ì¸í›„í†µì´ ìˆìœ¼ë©´ ìƒê¸°ë„ ê°ì—¼ ìš°ì„ 
                throat_diseases = [c for c in candidates 
                                 if any(keyword in c.get('disease', '').lower() or keyword in c.get('symptoms', '').lower()
                                       for keyword in ['ì¸í›„', 'ëª©', 'ìƒê¸°ë„', 'í¸ë„'])]
                other_diseases = [c for c in candidates if c not in throat_diseases]
                return throat_diseases + other_diseases
        
        # ğŸ”¥ ê¸°ë³¸ì ìœ¼ë¡œëŠ” ëª¨ë“  í›„ë³´ ìœ ì§€ (ë„ˆë¬´ ê°•í•œ í•„í„°ë§ ë°©ì§€)
        return candidates
    
    def _apply_symptom_weights(self, symptoms_text: str, diseases: List[Dict]) -> List[Dict]:
        """ì¦ìƒ ê°€ì¤‘ì¹˜ ì ìš©í•˜ì—¬ ì§ˆë³‘ ì¬ì •ë ¬"""
        symptoms_lower = symptoms_text.lower()
        
        for disease in diseases:
            base_score = disease.get('score', 0)
            symptom_boost = 0
            
            # í•µì‹¬ ì¦ìƒ ë§¤ì¹­ ê³„ì‚°
            disease_symptoms = disease.get('symptoms', '').lower()
            
            for symptom, weight in self.symptom_weights.items():
                if symptom in symptoms_lower and symptom in disease_symptoms:
                    symptom_boost += weight
            
            # ìµœì¢… ì ìˆ˜ ê³„ì‚°
            disease['confidence'] = min(base_score + symptom_boost, 1.0)
        
        # ì‹ ë¢°ë„ ê¸°ì¤€ìœ¼ë¡œ ì¬ì •ë ¬
        return sorted(diseases, key=lambda x: x.get('confidence', 0), reverse=True)
    
    def _prioritize_common_diseases(self, symptoms_text: str, diseases: List[Dict]) -> List[Dict]:
        """ğŸ”¥ ê°ê¸°/ì½”ë¡œë‚˜ ë“± ì¼ë°˜ì  ì§ˆë³‘ ìš°ì„  ì§„ë‹¨"""
        symptoms_lower = symptoms_text.lower()
        
        # ê°ê¸°/ë…ê° ê´€ë ¨ ì¦ìƒ ì²´í¬
        cold_symptoms = ["ê¸°ì¹¨", "ì½§ë¬¼", "ì¸í›„í†µ", "ë°œì—´", "ë‘í†µ", "ì—´", "ë¨¸ë¦¬"]
        cold_match_count = sum(1 for symptom in cold_symptoms if symptom in symptoms_lower)
        
        # ê°ê¸° ì¦ìƒì´ 2ê°œ ì´ìƒì´ë©´ ê°ê¸°/ë…ê°ì„ ìƒìœ„ë¡œ ì˜¬ë¦¼
        if cold_match_count >= 2:
            cold_diseases = []
            other_diseases = []
            
            for disease in diseases:
                disease_name = disease.get('disease', '').lower()
                if any(keyword in disease_name for keyword in ['ê°ê¸°', 'ë…ê°', 'ì¸í”Œë£¨ì—”ì', 'ìƒê¸°ë„','ìƒê¸°ë„ ê°ì—¼','ë§Œì„± ê¸°ì¹¨','ëƒ‰ë°©ë³‘','ê¸‰ì„±ê¸°ê´€ì§€ì—¼','íë ´', 'ê¸°ê´€ì§€ì—¼','ì¸í›„ì—¼', 'ê¸‰ì„± ìƒê¸°ë„ ê°ì—¼']):
                    # ê°ê¸°/ë…ê° ì§ˆë³‘ì— ì¶”ê°€ ê°€ì¤‘ì¹˜
                    disease['confidence'] = disease.get('confidence', 0) + 0.3
                    cold_diseases.append(disease)
                else:
                    other_diseases.append(disease)
            
            # ê°ê¸° ì§ˆë³‘ì„ ì•ìœ¼ë¡œ ì •ë ¬
            prioritized = sorted(cold_diseases, key=lambda x: x.get('confidence', 0), reverse=True)
            prioritized.extend(sorted(other_diseases, key=lambda x: x.get('confidence', 0), reverse=True))
            
            logger.info(f"ğŸ”¥ ê°ê¸° ì¦ìƒ {cold_match_count}ê°œ ê°ì§€ - ê°ê¸°/ë…ê° ìš°ì„  ì§„ë‹¨")
            return prioritized
        
        return diseases
    
    def _generate_enhanced_final_diagnosis(self, candidates: List[Dict], symptoms_text: str, session: IntegratedSession) -> str:
        """ğŸ”¥ ê°•í™”ëœ ìµœì¢… ì§„ë‹¨ - ì´ˆê¸° ì¦ìƒ ì •ë³´ í™œìš©"""
        
        if not candidates:
            return "âš ï¸ ê´€ë ¨ëœ ì§ˆë³‘ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜ë£Œ ì „ë¬¸ê°€ì—ê²Œ ìƒë‹´ì„ ë°›ìœ¼ì‹œê¸° ë°”ëë‹ˆë‹¤."
        
        top_candidate = candidates[0]
        disease_name = top_candidate.get('disease', '')
        confidence = top_candidate.get('confidence', 0)
        
        # ğŸ”¥ ì´ˆê¸° ì¦ìƒ ì •ë³´ í™œìš©
        initial_symptoms = session.context.get("initial_symptoms_text", symptoms_text)
        
        # ğŸ”¥ ì½”ë¡œë‚˜19 ì£¼ì˜ì‚¬í•­ íŒë‹¨
        covid_similar_diseases = ['ê°ê¸°', 'ìƒê¸°ë„', 'ë…ê°', 'ì¸í”Œë£¨ì—”ì', 'ê¸°ê´€ì§€ì—¼', 'íë ´','ë§Œì„± ê¸°ì¹¨','ëƒ‰ë°©ë³‘','ê¸‰ì„±ê¸°ê´€ì§€ì—¼','íë ´', 'ê¸°ê´€ì§€ì—¼','ì¸í›„ì—¼', 'ê¸‰ì„± ìƒê¸°ë„ ê°ì—¼']
        needs_covid_warning = any(keyword in disease_name.lower() for keyword in covid_similar_diseases)
        
        # ğŸ”¥ ê°•í™”ëœ ì§„ë‹¨ í”„ë¡¬í”„íŠ¸
        enhanced_prompt = f"""ë‹¹ì‹ ì€ ì „ë¬¸ ì˜ë£Œì§„ì…ë‹ˆë‹¤. ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•œ ì§„ë‹¨ì„ ë‚´ë ¤ì£¼ì„¸ìš”.

í™˜ì ì¦ìƒ: {initial_symptoms}
ê°€ì¥ ê°€ëŠ¥ì„± ë†’ì€ ì§ˆë³‘: {disease_name} (ì‹ ë¢°ë„: {confidence:.2f})
ê¸°íƒ€ í›„ë³´: {', '.join([c.get('disease', '') for c in candidates[1:3]])}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:

ğŸ¯ **ìµœì¢… ì§„ë‹¨**: {disease_name}

ğŸ“‹ **ì§„ë‹¨ ê·¼ê±°**:
- í™˜ìë¶„ê»˜ì„œ ë³´ê³ í•˜ì‹  ì¦ìƒë“¤ì´ ì´ ì§ˆë³‘ì˜ íŠ¹ì§•ì ì¸ ì¦ìƒê³¼ ì¼ì¹˜í•©ë‹ˆë‹¤.
- [êµ¬ì²´ì ì¸ ì¦ìƒ ë§¤ì¹­ ì„¤ëª…]

ğŸ“– **ì§ˆë³‘ ì„¤ëª…**:
- [ì§ˆë³‘ì— ëŒ€í•œ ê°„ë‹¨í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ ì„¤ëª…]

ğŸ’¡ **ê´€ë¦¬ ë°©ë²•**:
- [ìƒí™œ ê´€ë¦¬ ë° ëŒ€ì²˜ ë°©ë²•]

ğŸ¥ **ë³‘ì› ì§„ë£Œ ê¶Œìœ **:
- [ë³‘ì› ë°©ë¬¸ ê¶Œìœ  ë° ì‘ê¸‰ìƒí™© íŒë‹¨]

**ì°¸ê³ **: ì´ ì§„ë‹¨ì€ ì¦ìƒ ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ í•œ ì°¸ê³ ìš© ì •ë³´ì…ë‹ˆë‹¤."""

        # ğŸ”¥ ì½”ë¡œë‚˜19 ì£¼ì˜ì‚¬í•­ ì¶”ê°€
        if needs_covid_warning:
            enhanced_prompt += f"""

ğŸš¨ **COVID-19 ê°ë³„ ì£¼ì˜ì‚¬í•­** ğŸš¨
ì§„ë‹¨ëœ ì§ˆë³‘ì˜ ì¦ìƒì€ COVID-19ì™€ ìœ ì‚¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ê°€ëŠ¥í•˜ë©´ ì½”ë¡œë‚˜19 ê²€ì‚¬ë¥¼ ë°›ìœ¼ì‹œê¸° ë°”ëë‹ˆë‹¤
- íƒ€ì¸ê³¼ì˜ ì ‘ì´‰ì„ ìµœì†Œí™”í•˜ê³  ë§ˆìŠ¤í¬ë¥¼ ì°©ìš©í•˜ì„¸ìš”
- í˜¸í¡ê³¤ë€ì´ë‚˜ ê³ ì—´ ì§€ì† ì‹œ ì¦‰ì‹œ ë³‘ì›ì— ë°©ë¬¸í•˜ì„¸ìš”"""

        try:
            response = self.exaone.generate_response(enhanced_prompt)
            
            # ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ (ì§„ë‹¨ëœ ì§ˆë³‘ê³¼ ì‚¬ìš©ì ì¦ìƒ ì €ì¥)
            session.context["last_final_diagnosis"] = disease_name
            session.update_disease_context(disease_name, [initial_symptoms], "disease_diagnosis")
            logger.info(f"ğŸ¥ ê°•í™”ëœ ì§„ë‹¨ ì™„ë£Œ: {disease_name} (ì‹ ë¢°ë„: {confidence:.2f})")
            
            return response
            
        except Exception as e:
            logger.error(f"ê°•í™”ëœ ì§„ë‹¨ ìƒì„± ì˜¤ë¥˜: {e}")
            return f"âš ï¸ ì§„ë‹¨ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    # ë‚˜ë¨¸ì§€ ë©”ì„œë“œë“¤ì€ ê¸°ì¡´ê³¼ ë™ì¼...
    def _search_similar_diseases(self, query: str, top_k: int = 8) -> List[Dict]:
        """ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ìœ ì‚¬í•œ ì§ˆë³‘ ì°¾ê¸°"""
        try:
            query_embedding = self.embedding_model.encode([query])
            faiss.normalize_L2(query_embedding)
            
            scores, indices = self.disease_index_full.search(query_embedding, top_k)
            
            results = []
            for i, idx in enumerate(indices[0]):
                if 0 <= idx < len(self.disease_meta):
                    disease_data = self.disease_meta[idx].copy()
                    disease_data['score'] = float(scores[0][i])
                    results.append(disease_data)
            
            return results
        except Exception as e:
            logger.error(f"ì§ˆë³‘ ë²¡í„° ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    
    def _get_rag_context(self, query: str) -> str:
        """RAG ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°"""
        try:
            if self.rag_manager:
                context = self.rag_manager.get_relevant_context(query, top_k=2)
                return context[:200] + "..."
            return "ì¶”ê°€ ì˜ë£Œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        except Exception as e:
            logger.error(f"RAG ì»¨í…ìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
            return "ê´€ë ¨ ì˜ë£Œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    def _format_disease_list(self, diseases: List[Dict]) -> str:
        """ì§ˆë³‘ ëª©ë¡ í¬ë§·íŒ…"""
        formatted = []
        for i, disease in enumerate(diseases[:3], 1):
            name = disease.get('disease', 'ì•Œ ìˆ˜ ì—†ìŒ')
            confidence = disease.get('confidence', 0)
            formatted.append(f"{i}. {name} (ì‹ ë¢°ë„: {confidence:.2f})")
        return "\n".join(formatted)
    
    def get_disease_info(self, disease_query: str) -> str:
        """ì§ˆë³‘ ì •ë³´ ê²€ìƒ‰"""
        try:
            rag_context = self._get_rag_context(disease_query)
            similar_diseases = self._search_similar_diseases(disease_query, top_k=3)
            
            system_prompt = """ë‹¹ì‹ ì€ ì˜ë£Œ ì •ë³´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì§ˆë³‘ì— ëŒ€í•œ ì •í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”."""
            
            prompt = f"""ì§ˆë³‘ëª…: {disease_query}

ê´€ë ¨ ì˜ë£Œ ì •ë³´:
{rag_context}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:

ğŸ“– **ì§ˆë³‘ ê°œìš”**:
- [ì§ˆë³‘ì— ëŒ€í•œ ê°„ë‹¨í•œ ì„¤ëª…]

ğŸ” **ì£¼ìš” ì¦ìƒ**:
- [ëŒ€í‘œì ì¸ ì¦ìƒë“¤]

ğŸ¯ **ì›ì¸**:
- [ë°œìƒ ì›ì¸]

ğŸ’¡ **ì˜ˆë°© ë° ê´€ë¦¬**:
- [ì˜ˆë°© ë°©ë²•ê³¼ ê´€ë¦¬ë²•]

ğŸ¥ **ì¹˜ë£Œ**:
- [ì¹˜ë£Œ ë°©ë²•]

**ì°¸ê³ **: ì •í™•í•œ ì§„ë‹¨ê³¼ ì¹˜ë£ŒëŠ” ì˜ë£Œì§„ê³¼ ìƒë‹´í•˜ì„¸ìš”."""
            
            response = self.exaone.generate_response(prompt, system_prompt)
            return response
            
        except Exception as e:
            logger.error(f"ì§ˆë³‘ ì •ë³´ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return f"âš ï¸ ì§ˆë³‘ ì •ë³´ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

# =============================================================================
# ë‚˜ë¨¸ì§€ í´ë˜ìŠ¤ë“¤ - ê¸°ì¡´ê³¼ ë™ì¼
# =============================================================================

class EnhancedIntentClassifier:
    """ê°•í™”ëœ ì˜ë„ ë¶„ë¥˜ê¸°"""
    
    def __init__(self, exaone_service):
        self.exaone = exaone_service
        
        self.intent_categories = {
            "symptom_medication": [
                "ì•„í”ˆë° ì•½", "ì•„í”„ë©´ ì•½", "ë¬´ìŠ¨ ì•½", "ì–´ë–¤ ì•½", "ì•½ ì¶”ì²œ", 
                "ë¨¹ì–´ì•¼", "ë³µìš©", "ì¹˜ë£Œì œ", "ë‘í†µì•½", "ê°ê¸°ì•½", "í•´ì—´ì œ",
                "ë¨¸ë¦¬ ì•„í”ˆë°", "ë°° ì•„í”ˆë°", "ì—´ ë‚˜ëŠ”ë°", "ê¸°ì¹¨ ë‚˜ëŠ”ë°"
            ],
            "disease_diagnosis": [
                "ì§„ë‹¨", "ë³‘", "ì§ˆë³‘", "ë¬´ìŠ¨ ë³‘", "ì–´ë–¤ ë³‘", "ì¦ìƒ",
                "ì•„í”„ë‹¤", "ì•„í”ˆ", "í†µì¦", "ì—´", "ê¸°ì¹¨", "ê°ê¸°"
            ],
            "disease_info": [
                "ì§ˆë³‘ì— ëŒ€í•´", "ë³‘ì— ëŒ€í•´", "ì›ì¸", "ì¹˜ë£Œë²•", "ì˜ˆë°©ë²•", 
                "ì•Œë ¤ì¤˜", "ì„¤ëª…", "ì´ë€", "ë¬´ì—‡"
            ],
            "medication_recommend": [
                "ì•½ ì¶”ì²œ", "ì²˜ë°©", "ì˜ì•½í’ˆ", "ì¹˜ë£Œì œ", "ì•½ë¬¼"
            ],
            "medication_info": [
                "ì•½ ì •ë³´", "ë¶€ì‘ìš©", "íš¨ëŠ¥", "ì„±ë¶„", "ìš©ë²•", "ìš©ëŸ‰", 
                "íƒ€ì´ë ˆë†€", "ê²Œë³´ë¦°", "ë‚™ì„¼"
            ],
            "disease_to_medication": [
                "ì•½", "ì²˜ë°©", "ì¹˜ë£Œì œ", "ë¨¹ìœ¼ë©´", "ë³µìš©"
            ],
            "reset": [
                "ì²˜ìŒìœ¼ë¡œ", "ì²˜ìŒë¶€í„°", "ë‹¤ì‹œ", "ë¦¬ì…‹", "reset", 
                "ì´ˆê¸°í™”", "ìƒˆë¡œ ì‹œì‘", "ê·¸ë§Œ"
            ],
            "general": [
                "ì•ˆë…•", "ê°ì‚¬", "ê³ ë§ˆì›Œ", "bye", "ì•ˆë…•í•˜ì„¸ìš”"
            ]
        }
        
        self.compound_patterns = [
            r'([ê°€-í£]+(?:ì•„í”„|ì•„í”ˆ|í†µì¦)).*(?:ì•½|ì•½í’ˆ|ë¨¹ì–´ì•¼|ë³µìš©)',
            r'(?:ë¨¸ë¦¬|ë‘í†µ|ë°°|ë³µí†µ|ì—´|ê¸°ì¹¨).*(?:ì•½|ì•½í’ˆ|ì¹˜ë£Œì œ)',
            r'(?:ê°ê¸°|ë…ê°|ëª¸ì‚´).*(?:ì•½|ì•½í’ˆ|ë¨¹ìœ¼ë©´)',
            r'([ê°€-í£]+(?:ë‚˜ëŠ”ë°|ë‚˜ì„œ)).*(?:ì•½|ì•½í’ˆ|ì–´ë–¤)'
        ]
    
    def classify_intent(self, message: str, session: IntegratedSession) -> str:
        """ê°•í™”ëœ ì˜ë„ ë¶„ë¥˜"""
        message_lower = message.lower()
        
        # 1. ì°¨ë³„í™” ì§ˆë¬¸ ëª¨ë“œ ìš°ì„  í™•ì¸
        if session.context["questioning_state"]["is_questioning"]:
            logger.info("ğŸ”¬ ì°¨ë³„í™” ì§ˆë¬¸ ì‘ë‹µ ëª¨ë“œ")
            return "diagnosis_followup"
        
        # 2. ì„¸ì…˜ ì´ˆê¸°í™” ìš”ì²­ ìš°ì„  ì²˜ë¦¬
        if any(keyword in message_lower for keyword in self.intent_categories["reset"]):
            logger.info("ğŸ”„ ì„¸ì…˜ ì´ˆê¸°í™” ìš”ì²­ ê°ì§€")
            return "reset"
        
        # 3. ë³µí•© ì˜ë„ íŒ¨í„´ ê²€ì‚¬
        for pattern in self.compound_patterns:
            if re.search(pattern, message):
                logger.info(f"ğŸ’Š ë³µí•© ì˜ë„ ê°ì§€: ì¦ìƒ ê¸°ë°˜ ì˜ì•½í’ˆ ì¶”ì²œ - {message}")
                return "symptom_medication"
        
        # 4. ì¦ìƒ í‚¤ì›Œë“œ + ì•½í’ˆ í‚¤ì›Œë“œ ë™ì‹œ ì¡´ì¬ ê²€ì‚¬
        symptom_words = ["ì•„í”„", "ì•„í”ˆ", "í†µì¦", "ì—´", "ê¸°ì¹¨", "ë‘í†µ", "ë³µí†µ", "ë¨¸ë¦¬", "ë°°"]
        medication_words = ["ì•½", "ì•½í’ˆ", "ë¨¹ì–´ì•¼", "ë³µìš©", "ì¹˜ë£Œì œ", "ì²˜ë°©"]
        
        has_symptom = any(word in message_lower for word in symptom_words)
        has_medication = any(word in message_lower for word in medication_words)
        
        if has_symptom and has_medication:
            logger.info(f"ğŸ’Š ì¦ìƒ+ì•½í’ˆ í‚¤ì›Œë“œ ë™ì‹œ ê°ì§€ - {message}")
            return "symptom_medication"
        
        # 5. ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì§ˆë³‘-ì˜ì•½í’ˆ ì—°ê³„ ê²€ì‚¬
        recent_disease = session.get_recent_diagnosis()
        if recent_disease:
            medication_keywords = ["ì•½", "ì•½í’ˆ", "ì²˜ë°©", "ì¶”ì²œ", "ë³µìš©", "ë¨¹ì–´ì•¼", "ì¹˜ë£Œì œ"]
            if any(keyword in message_lower for keyword in medication_keywords):
                logger.info(f"ğŸ”— ì§ˆë³‘-ì˜ì•½í’ˆ ì—°ê³„ ì˜ë„: {recent_disease} -> ì•½í’ˆ")
                return "disease_to_medication"
        
        # 6. ê¸°ë³¸ í‚¤ì›Œë“œ ë§¤ì¹­
        for intent, keywords in self.intent_categories.items():
            if intent in ["symptom_medication", "disease_to_medication", "reset"]:
                continue
                
            if any(keyword in message_lower for keyword in keywords):
                return intent
        
        # 7. EXAONE ê¸°ë°˜ ê³ ê¸‰ ë¶„ë¥˜
        return self._classify_with_exaone(message)
    
    def _classify_with_exaone(self, message: str) -> str:
        """EXAONE ê¸°ë°˜ ê³ ê¸‰ ì˜ë„ ë¶„ë¥˜"""
        system_prompt = """ë‹¹ì‹ ì€ ì˜ë£Œ ì±—ë´‡ì˜ ì˜ë„ ë¶„ë¥˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”:

1. symptom_medication: ì¦ìƒì„ ì„¤ëª…í•˜ë©´ì„œ ì•½ ì¶”ì²œì„ ìš”ì²­
2. disease_diagnosis: ì¦ìƒë§Œ ì„¤ëª…í•˜ë©° ì§ˆë³‘ ì§„ë‹¨ ìš”ì²­
3. disease_info: íŠ¹ì • ì§ˆë³‘ ì •ë³´ ìš”ì²­
4. medication_recommend: ì¼ë°˜ì ì¸ ì•½í’ˆ ì¶”ì²œ ìš”ì²­
5. medication_info: íŠ¹ì • ì•½í’ˆ ì •ë³´ ìš”ì²­  
6. general: ì¼ë°˜ì ì¸ ì¸ì‚¬ë‚˜ ëŒ€í™”

ë¶„ë¥˜ ê²°ê³¼ë§Œ ë‹µë³€í•˜ì„¸ìš”."""

        prompt = f"ì‚¬ìš©ì ë©”ì‹œì§€: '{message}'\në¶„ë¥˜ ê²°ê³¼:"
        
        try:
            response = self.exaone.generate_response(prompt, system_prompt)
            valid_intents = ["symptom_medication", "disease_diagnosis", "disease_info", 
                           "medication_recommend", "medication_info", "general"]
            
            for intent in valid_intents:
                if intent in response.lower():
                    return intent
            return "general"
            
        except Exception as e:
            logger.error(f"EXAONE ì˜ë„ ë¶„ë¥˜ ì˜¤ë¥˜: {e}")
            return "general"

class MedicationService:
    """ì˜ì•½í’ˆ ì„œë¹„ìŠ¤"""
    
    WARNING_MSG = "\n\nâš ï¸ **ì¤‘ìš”í•œ ì•ˆì „ ì •ë³´**:\n- ì´ ì •ë³´ëŠ” ì¼ë°˜ì ì¸ ì°¸ê³ ìš©ì…ë‹ˆë‹¤\n- ë³µìš© ì „ ë°˜ë“œì‹œ ì˜ì‚¬ë‚˜ ì•½ì‚¬ì™€ ìƒë‹´í•˜ì„¸ìš”\n- ì•Œë ˆë¥´ê¸°ë‚˜ ë‹¤ë¥¸ ì•½ë¬¼ê³¼ì˜ ìƒí˜¸ì‘ìš©ì„ í™•ì¸í•˜ì„¸ìš”\n- ì¦ìƒì´ ì§€ì†ë˜ë©´ ì¦‰ì‹œ ì˜ë£Œì§„ì—ê²Œ ì—°ë½í•˜ì„¸ìš”"
    
    def __init__(self, exaone_service: EXAONE, med_index: faiss.IndexFlatIP, 
                 med_meta: List[Dict], embedding_model: EmbeddingModel):
        self.exaone = exaone_service
        self.med_index = med_index
        self.med_meta = med_meta
        self.embedding_model = embedding_model
    
    def recommend_medication_by_symptoms(self, symptoms_text: str, session: IntegratedSession) -> str:
        """ì¦ìƒ ê¸°ë°˜ ì˜ì•½í’ˆ ì¶”ì²œ"""
        
        # 1. ì‚¬ìš©ì ì •ë³´ ìˆ˜ì§‘
        self._collect_user_medication_info(session)
        profile = session.context["user_medication_profile"]
        
        # 2. ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ê´€ë ¨ ì˜ì•½í’ˆ ì°¾ê¸°
        similar_meds = self._search_similar_medications(symptoms_text, top_k=5)
        
        # 3. ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ í™œìš©
        context_info = ""
        if similar_meds:
            context_info = "\nğŸ’Š ê´€ë ¨ ì˜ì•½í’ˆ ë°ì´í„°:\n"
            for i, med in enumerate(similar_meds, 1):
                name = med.get('name', '')
                efficacy = med.get('efficacy', '')
                context_info += f"{i}. {name}: {efficacy[:100]}...\n"
        
        # 4. EXAONEì„ ì´ìš©í•œ ì¶”ì²œ
        system_prompt = """ë‹¹ì‹ ì€ ìˆ™ë ¨ëœ ì•½ì‚¬ì´ë©°, ì¼ë°˜ì˜ì•½í’ˆì— ëŒ€í•œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì‚¬ìš©ìì˜ ì¦ìƒì— ëŒ€í•´ ì ì ˆí•œ ì¼ë°˜ì˜ì•½í’ˆì„ ìµœëŒ€ 3ê°œê¹Œì§€ ì¶”ì²œí•˜ì‹­ì‹œì˜¤.
ê´€ë ¨ ì˜ì•½í’ˆ ë°ì´í„°ê°€ ìˆë‹¤ë©´ ì´ë¥¼ ì°¸ê³ í•˜ë˜, ì‚¬ìš©ì ì¡°ê±´ì— ë§ëŠ” ì•ˆì „í•œ ì•½í’ˆì„ ì¶”ì²œí•´ì£¼ì„¸ìš”.
ì£¼ì˜ì‚¬í•­ê³¼ ë¶€ì‘ìš©ì€ ì‚¬ìš©ì ì•ˆì „ì„ ìœ„í•´ ìì„¸íˆ ì„¤ëª…í•˜ì‹­ì‹œì˜¤.

ê° ì¶”ì²œ ì•½ì— ëŒ€í•´ ë‹¤ìŒ ì •ë³´ë¥¼ í¬í•¨í•˜ì‹­ì‹œì˜¤:
1. ì•½ ì´ë¦„  
2. ì¶”ì²œ ì´ìœ   
3. ë³µìš©ë²•  
4. ì£¼ì˜ì‚¬í•­  
5. ë¶€ì‘ìš©"""

        prompt = f"""
ì‚¬ìš©ì ì •ë³´:
- ì—°ë ¹ëŒ€: {profile.get('age_group', 'ì„±ì¸')}
- ì„ì‹  ì—¬ë¶€: {"ì˜ˆ" if profile.get('is_pregnant') else "ì•„ë‹ˆì˜¤"}
- ê¸°ì €ì§ˆí™˜: {', '.join(profile.get('chronic_conditions', [])) if profile.get('chronic_conditions') else 'ì—†ìŒ'}

ì‚¬ìš©ì ì¦ìƒ: {symptoms_text}
{context_info}

ìœ„ ì¡°ê±´ì„ ê³ ë ¤í•˜ì—¬ ì•ˆì „í•˜ê³  ì ì ˆí•œ ì¼ë°˜ì˜ì•½í’ˆì„ ì¶”ì²œí•´ì£¼ì„¸ìš”."""

        try:
            response = self.exaone.generate_response(prompt, system_prompt)
            
            # ì¶”ì²œëœ ì•½í’ˆ ì •ë³´ ì¶”ì¶œí•˜ì—¬ ì„¸ì…˜ì— ì €ì¥
            medications = self._extract_medications_from_response(response)
            if medications:
                session.update_medication_context(medications)
                logger.info(f"ğŸ’Š ì˜ì•½í’ˆ ì¶”ì²œ ì™„ë£Œ: {len(medications)}ê°œ")
            
            return response + self.WARNING_MSG
            
        except Exception as e:
            logger.error(f"ì˜ì•½í’ˆ ì¶”ì²œ ì˜¤ë¥˜: {e}")
            return "âš ï¸ ì˜ì•½í’ˆ ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
    
    def get_medication_info(self, medication_name: str) -> str:
        """ì˜ì•½í’ˆ ì •ë³´ ì œê³µ"""
        
        # ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ê´€ë ¨ ì˜ì•½í’ˆ ì°¾ê¸°
        related_meds = self._search_similar_medications(medication_name, top_k=2)
        
        context_info = ""
        if related_meds:
            context_info = "\nğŸ’Š ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´:\n"
            for med in related_meds:
                name = med.get('name', '')
                efficacy = med.get('efficacy', '')
                context_info += f"- {name}: {efficacy}\n"
        
        system_prompt = """ë‹¹ì‹ ì€ ì „ë¬¸ ì•½ì‚¬ì…ë‹ˆë‹¤.

ì‚¬ìš©ìê°€ ì§ˆë¬¸í•œ ì•½í’ˆì„ ì¤‘ì‹¬ìœ¼ë¡œ ì •í™•í•˜ê³  ìƒì„¸í•œ ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.
ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´ê°€ ìˆë‹¤ë©´ ì´ë¥¼ ì°¸ê³ í•˜ë˜, í¬ê´„ì ì¸ ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.

ê° ì•½í’ˆì— ëŒ€í•´ ë‹¤ìŒ ì •ë³´ë¥¼ í¬í•¨í•˜ì‹­ì‹œì˜¤:
1. ì•½ ì´ë¦„ê³¼ ì£¼ìš” ì„±ë¶„
2. íš¨ëŠ¥/íš¨ê³¼
3. ìš©ë²•/ìš©ëŸ‰  
4. ì£¼ì˜ì‚¬í•­
5. ë¶€ì‘ìš©
6. ìƒí˜¸ì‘ìš©"""

        prompt = f"""
ì‚¬ìš©ìê°€ ì§ˆë¬¸í•œ ì˜ì•½í’ˆ: {medication_name}
{context_info}

ìœ„ ì˜ì•½í’ˆì— ëŒ€í•œ ìƒì„¸í•œ ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”."""

        try:
            response = self.exaone.generate_response(prompt, system_prompt)
            return response + self.WARNING_MSG
            
        except Exception as e:
            logger.error(f"ì˜ì•½í’ˆ ì •ë³´ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return f"âš ï¸ {medication_name}ì— ëŒ€í•œ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    def recommend_by_disease_symptoms(self, disease: str, symptoms: List[str], session: IntegratedSession) -> str:
        """ì§ˆë³‘-ì¦ìƒ ê¸°ë°˜ ì˜ì•½í’ˆ ì¶”ì²œ"""
        
        # ì§ˆë³‘ê³¼ ì¦ìƒì„ ì¡°í•©í•œ ì¿¼ë¦¬ ìƒì„±
        symptoms_text = ", ".join(symptoms) if symptoms else ""
        combined_query = f"{disease} ì¦ìƒ: {symptoms_text}"
        
        logger.info(f"ğŸ”— ì§ˆë³‘-ì˜ì•½í’ˆ ì—°ê³„ ì¶”ì²œ: {combined_query}")
        
        # ê¸°ì¡´ ë¡œì§ì„ ê·¸ëŒ€ë¡œ í˜¸ì¶œ
        return self.recommend_medication_by_symptoms(combined_query, session)
    
    def _collect_user_medication_info(self, session: IntegratedSession):
        """ì‚¬ìš©ì ì˜ì•½í’ˆ ì •ë³´ ìˆ˜ì§‘"""
        profile = session.context["user_medication_profile"]
        
        # CLI í™˜ê²½ì—ì„œëŠ” ê¸°ë³¸ê°’ ì‚¬ìš©
        if not profile.get("age_group"):
            profile["age_group"] = "ì„±ì¸"
        if profile.get("is_pregnant") is None:
            profile["is_pregnant"] = False
        if not profile.get("chronic_conditions"):
            profile["chronic_conditions"] = []
    
    def _search_similar_medications(self, query: str, top_k: int = 3) -> List[Dict]:
        """ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ìœ ì‚¬í•œ ì˜ì•½í’ˆ ì°¾ê¸°"""
        try:
            query_embedding = self.embedding_model.encode([query])
            faiss.normalize_L2(query_embedding)
            
            scores, indices = self.med_index.search(query_embedding, top_k)
            
            results = []
            for idx in indices[0]:
                if 0 <= idx < len(self.med_meta):
                    results.append(self.med_meta[idx])
            
            return results
        except Exception as e:
            logger.error(f"ì˜ì•½í’ˆ ë²¡í„° ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    
    def _extract_medications_from_response(self, response: str) -> List[Dict]:
        """ì‘ë‹µì—ì„œ ì˜ì•½í’ˆ ì •ë³´ ì¶”ì¶œ"""
        medications = []
        
        # ì˜ì•½í’ˆëª… íŒ¨í„´ ë§¤ì¹­ ì‹œë„
        med_patterns = [
            r'1\.\s*ì•½\s*ì´ë¦„[:\s]*([ê°€-í£A-Za-z0-9\s]+)',
            r'ì•½\s*ì´ë¦„[:\s]*([ê°€-í£A-Za-z0-9\s]+)',
            r'ì¶”ì²œ\s*ì•½[:\s]*([ê°€-í£A-Za-z0-9\s]+)',
            r'(\w+ì •|\w+ìº¡ìŠ|\w+ì‹œëŸ½)',
            r'(íƒ€ì´ë ˆë†€|ê²Œë³´ë¦°|ë‚™ì„¼|ì´ë¶€í”„ë¡œíœ|ì•„ìŠ¤í”¼ë¦°|ì• ë“œë¹Œ|ë¶€ë£¨íœ)'
        ]
        
        for pattern in med_patterns:
            matches = re.finditer(pattern, response, re.IGNORECASE)
            for match in matches:
                med_name = match.group(1).strip()
                if med_name and len(med_name) > 1:
                    medications.append({
                        "name": med_name,
                        "source": "llm_recommendation",
                        "response_context": response[:200]
                    })
        
        # ì¤‘ë³µ ì œê±°
        seen_names = set()
        unique_medications = []
        for med in medications:
            if med["name"] not in seen_names:
                seen_names.add(med["name"])
                unique_medications.append(med)
        
        return unique_medications[:3]

# =============================================================================
# ğŸš€ ìˆ˜ì •ëœ í†µí•© ì±„íŒ… ì„œë¹„ìŠ¤ v6
# =============================================================================

class OptimizedIntegratedChatServiceV6:
    """ğŸš€ ìˆ˜ì •ëœ í†µí•© ì±„íŒ… ì„œë¹„ìŠ¤ v6 - ìŠ¤ë§ˆíŠ¸í•œ ì°¨ë³„í™” ì§ˆë¬¸"""
    
    def __init__(self):
        """ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        start_time = datetime.now()
        logger.info("ğŸš€ ìˆ˜ì •ëœ í†µí•© ì˜ë£Œ ì±—ë´‡ ì„œë¹„ìŠ¤ v6 ì´ˆê¸°í™” ì‹œì‘...")
        
        # 1. ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
        self.embedding_model = EmbeddingModel()
        
        # 2. EXAONE LLM ì´ˆê¸°í™”
        self.exaone = EXAONE()
        
        # 3. ìµœì í™”ëœ RAG ë§¤ë‹ˆì € ì´ˆê¸°í™”
        self.rag_manager = OptimizedRAGIndexManager(self.embedding_model)
        self.rag_manager.load_rag_data()
        
        # 4. ì§ˆë³‘ ë°ì´í„° ë¡œë“œ
        disease_files, medication_files = discover_csv_files()
        
        if disease_files:
            self.disease_index_key, self.disease_index_full, self.disease_meta = optimized_load_disease_indexes(
                disease_files, self.embedding_model
            )
            self.disease_service = EnhancedDiseaseService(
                self.exaone, self.disease_index_key, self.disease_index_full,
                self.disease_meta, self.embedding_model, self.rag_manager
            )
        else:
            self.disease_service = None
            logger.warning("âš ï¸ ì§ˆë³‘ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # 5. ì˜ì•½í’ˆ ë°ì´í„° ë¡œë“œ
        if medication_files:
            self.med_index, self.med_meta = optimized_load_medication_index(
                medication_files, self.embedding_model
            )
            self.medication_service = MedicationService(
                self.exaone, self.med_index, self.med_meta, self.embedding_model
            )
        else:
            self.medication_service = None
            logger.warning("âš ï¸ ì˜ì•½í’ˆ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # 6. ê°•í™”ëœ ì˜ë„ ë¶„ë¥˜ê¸° ì´ˆê¸°í™”
        self.intent_classifier = EnhancedIntentClassifier(self.exaone)
        
        # ì´ˆê¸°í™” ì™„ë£Œ ì‹œê°„ ê³„ì‚°
        init_time = datetime.now() - start_time
        
        # ì‚¬ì „ ìƒì„±ëœ ì¸ë±ìŠ¤ ì‚¬ìš© ì—¬ë¶€ í™•ì¸
        using_prebuilt = self.rag_manager.use_prebuilt and PreBuiltIndexLoader.check_indexes_available()
        
        logger.info("âœ… ìˆ˜ì •ëœ í†µí•© ì˜ë£Œ ì±—ë´‡ ì„œë¹„ìŠ¤ v6 ì´ˆê¸°í™” ì™„ë£Œ!")
        logger.info(f"â±ï¸ ì´ˆê¸°í™” ì‹œê°„: {init_time}")
        logger.info(f"ğŸš€ ì‚¬ì „ ìƒì„± ì¸ë±ìŠ¤ ì‚¬ìš©: {'ì˜ˆ' if using_prebuilt else 'ì•„ë‹ˆì˜¤'}")
        
        if using_prebuilt:
            index_info = PreBuiltIndexLoader.get_index_info()
            if index_info:
                logger.info(f"ğŸ“Š ì¸ë±ìŠ¤ ìƒì„±ì¼: {index_info.get('created_at', 'Unknown')}")
                logger.info(f"ğŸ“Š ì¸ë±ìŠ¤ ë²„ì „: {index_info.get('version', 'Unknown')}")
        
        logger.info(f"ğŸ“Š ë¡œë“œëœ ë°ì´í„°:")
        logger.info(f"   - RAG Q&A: {len(self.rag_manager.qa_documents)}ê°œ")
        logger.info(f"   - RAG ì˜ë£Œë¬¸ì„œ: {len(self.rag_manager.medical_documents)}ê°œ")
        if self.disease_service:
            logger.info(f"   - ì§ˆë³‘ ë°ì´í„°: {len(self.disease_meta)}ê°œ")
        if self.medication_service:
            logger.info(f"   - ì˜ì•½í’ˆ ë°ì´í„°: {len(self.med_meta)}ê°œ")
    
    def process_message(self, message: str, session: IntegratedSession) -> str:
        """ğŸ”¥ ìˆ˜ì •ëœ ë©”ì‹œì§€ ì²˜ë¦¬"""
        
        try:
            # 1. ê°•í™”ëœ ì˜ë„ ë¶„ë¥˜
            intent = self.intent_classifier.classify_intent(message, session)
            logger.info(f"ğŸ¯ ì˜ë„ ë¶„ë¥˜ ê²°ê³¼: {intent}")
            
            # 2. ì„¸ì…˜ ì´ˆê¸°í™” ì²˜ë¦¬
            if intent == "reset":
                session.reset_session()
                return "ğŸ”„ ì„¸ì…˜ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤. ì²˜ìŒë¶€í„° ë‹¤ì‹œ ì‹œì‘í•´ì£¼ì„¸ìš”!"
            
            # 3. ì°¨ë³„í™” ì§ˆë¬¸ í›„ì† ë‹µë³€ ì²˜ë¦¬
            elif intent == "diagnosis_followup":
                if self.disease_service:
                    response = self.disease_service.process_followup_answer(message, session)
                else:
                    response = "âš ï¸ ì§ˆë³‘ ì§„ë‹¨ ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            # 4. ì¦ìƒ ê¸°ë°˜ ì˜ì•½í’ˆ ì¶”ì²œ
            elif intent == "symptom_medication":
                if self.medication_service:
                    response = self.medication_service.recommend_medication_by_symptoms(message, session)
                else:
                    response = "âš ï¸ ì˜ì•½í’ˆ ì¶”ì²œ ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            # 5. ê¸°ì¡´ ì˜ë„ë“¤ ì²˜ë¦¬
            elif intent == "disease_diagnosis":
                if self.disease_service:
                    response = self.disease_service.diagnose_disease(message, session)
                else:
                    response = "âš ï¸ ì§ˆë³‘ ì§„ë‹¨ ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            elif intent == "disease_info":
                if self.disease_service:
                    disease_name = self._extract_disease_name(message)
                    response = self.disease_service.get_disease_info(disease_name or message)
                else:
                    response = "âš ï¸ ì§ˆë³‘ ì •ë³´ ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            elif intent == "medication_recommend":
                if self.medication_service:
                    response = self.medication_service.recommend_medication_by_symptoms(message, session)
                else:
                    response = "âš ï¸ ì˜ì•½í’ˆ ì¶”ì²œ ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            elif intent == "medication_info":
                if self.medication_service:
                    med_name = self._extract_medication_name(message)
                    response = self.medication_service.get_medication_info(med_name or message)
                else:
                    response = "âš ï¸ ì˜ì•½í’ˆ ì •ë³´ ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            elif intent == "disease_to_medication":
                recent_disease = session.get_recent_diagnosis()
                if recent_disease and self.medication_service:
                    symptoms = session.get_disease_symptoms(recent_disease)
                    response = self.medication_service.recommend_by_disease_symptoms(
                        recent_disease, symptoms, session
                    )
                else:
                    response = "ë¨¼ì € ì¦ìƒì„ ì•Œë ¤ì£¼ì‹œë©´ ì§ˆë³‘ì„ ì§„ë‹¨í•œ í›„ ì ì ˆí•œ ì•½í’ˆì„ ì¶”ì²œí•´ë“œë¦´ê²Œìš”!"
            
            else:  # general
                response = self._handle_general_message(message)
            
            # 6. ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            session.add_message(message, response, intent)
            
            return response
            
        except Exception as e:
            logger.error(f"ë©”ì‹œì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            traceback.print_exc()
            return "âš ï¸ ì£„ì†¡í•©ë‹ˆë‹¤. ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
    
    def _extract_disease_name(self, message: str) -> str:
        """ë©”ì‹œì§€ì—ì„œ ì§ˆë³‘ëª… ì¶”ì¶œ"""
        patterns = [
            r'([ê°€-í£]+(?:ë³‘|ì—¼|ì¦|ì•”))',
            r'([ê°€-í£]+ì— ëŒ€í•´)',
            r'([ê°€-í£]+ì´ë€)',
            r'([ê°€-í£]+ì„¤ëª…)'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, message)
            if match:
                return match.group(1).replace('ì— ëŒ€í•´', '').replace('ì´ë€', '').replace('ì„¤ëª…', '')
        
        return ""
    
    def _extract_medication_name(self, message: str) -> str:
        """ë©”ì‹œì§€ì—ì„œ ì˜ì•½í’ˆëª… ì¶”ì¶œ"""
        patterns = [
            r'([ê°€-í£A-Za-z0-9]+(?:ì •|ìº¡ìŠ|ì‹œëŸ½))',
            r'(íƒ€ì´ë ˆë†€|ê²Œë³´ë¦°|ë‚™ì„¼|ì´ë¶€í”„ë¡œíœ|ì•„ìŠ¤í”¼ë¦°|ì• ë“œë¹Œ|ë¶€ë£¨íœ)',
            r'([ê°€-í£A-Za-z0-9]+)(?:\s*(?:ì•½|ì˜ì•½í’ˆ|ì•½í’ˆ))'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, message)
            if match:
                return match.group(1)
        
        return ""
    
    def _handle_general_message(self, message: str) -> str:
        """ì¼ë°˜ ë©”ì‹œì§€ ì²˜ë¦¬"""
        greetings = ["ì•ˆë…•", "hello", "hi", "ì•ˆë…•í•˜ì„¸ìš”"]
        thanks = ["ê°ì‚¬", "ê³ ë§ˆì›Œ", "thank"]
        
        message_lower = message.lower()
        
        # ì‚¬ì „ ìƒì„±ëœ ì¸ë±ìŠ¤ ì‚¬ìš© ì—¬ë¶€ í™•ì¸
        using_prebuilt = self.rag_manager.use_prebuilt and PreBuiltIndexLoader.check_indexes_available()
        speed_info = "ğŸš€ ì‚¬ì „ ìƒì„±ëœ ì¸ë±ìŠ¤ ì‚¬ìš© (5ì´ˆ ë¡œë”©)" if using_prebuilt else "âš ï¸ ì‹¤ì‹œê°„ ì¸ë±ìŠ¤ ìƒì„± (16ë¶„ ë¡œë”©)"
        
        if any(greet in message_lower for greet in greetings):
            return f"""ì•ˆë…•í•˜ì„¸ìš”! ìˆ˜ì •ëœ ì˜ë£Œ ì±—ë´‡ v6ì…ë‹ˆë‹¤. 

ğŸ” **ì´ìš© ê°€ëŠ¥í•œ ê¸°ëŠ¥**:
â€¢ ì¦ìƒ ì„¤ëª… â†’ ì§ˆë³‘ ì§„ë‹¨ (ğŸ”¥ ìŠ¤ë§ˆíŠ¸í•œ ì°¨ë³„í™” ì§ˆë¬¸)
â€¢ ì§ˆë³‘ ì§„ë‹¨ í›„ "ì–´ë–¤ ì•½?" â†’ ì˜ì•½í’ˆ ì¶”ì²œ  
â€¢ ì§ˆë³‘ ì •ë³´ ê²€ìƒ‰ (RAG ê¸°ë°˜)
â€¢ ì˜ì•½í’ˆ ì •ë³´ ê²€ìƒ‰
â€¢ "ì²˜ìŒìœ¼ë¡œ" â†’ ì„¸ì…˜ ì´ˆê¸°í™”

ğŸ”¥ **ìˆ˜ì •ëœ ê¸°ëŠ¥**:
â€¢ ì¤‘ë³µ ì§ˆë¬¸ ë°©ì§€ - ì´ë¯¸ ì–¸ê¸‰í•œ ì¦ìƒì€ ë‹¤ì‹œ ë¬»ì§€ ì•ŠìŒ
â€¢ ì„¸ì…˜ ìƒíƒœ ê°œì„  - ì´ˆê¸° ì¦ìƒ ì •ë³´ ìœ ì§€
â€¢ í•„í„°ë§ ë¡œì§ ê°•í™” - ë¹ˆ ê²°ê³¼ ë°©ì§€

ğŸ“š **ì§€ì‹ ë² ì´ìŠ¤**: 6ê°œ clean_ íŒŒì¼ RAG + ì§ˆë³‘/ì˜ì•½í’ˆ ë²¡í„° DB
ğŸ§  **AI ëª¨ë¸**: EXAONE 3.5:7.8b + KM-BERT
{speed_info}

ì–´ë–¤ ì¦ìƒì´ ìˆìœ¼ì‹ ê°€ìš”?"""
        elif any(thank in message_lower for thank in thanks):
            return "ë„ì›€ì´ ë˜ì…¨ë‹¤ë‹ˆ ê¸°ì©ë‹ˆë‹¤! ë‹¤ë¥¸ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ì£¼ì„¸ìš”."
        else:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ì˜ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì¦ìƒì„ ì„¤ëª…í•´ì£¼ì‹œê±°ë‚˜ ì§ˆë³‘/ì˜ì•½í’ˆì— ëŒ€í•´ êµ¬ì²´ì ìœ¼ë¡œ ë¬¸ì˜í•´ì£¼ì„¸ìš”."

# =============================================================================
# CLI í…ŒìŠ¤íŠ¸ìš© ë©”ì¸ í•¨ìˆ˜
# =============================================================================

def main():
    """ìˆ˜ì •ëœ CLI í…ŒìŠ¤íŠ¸ ë©”ì¸ í•¨ìˆ˜"""
    print("="*80)
    print("ğŸš€ ìˆ˜ì •ëœ í†µí•© ì˜ë£Œ ì±—ë´‡ v6 - ìŠ¤ë§ˆíŠ¸í•œ ì°¨ë³„í™” ì§ˆë¬¸ ì‹œìŠ¤í…œ")
    print("ğŸ”¥ ì£¼ìš” ìˆ˜ì •ì‚¬í•­:")
    print("   â€¢ ì¤‘ë³µ ì§ˆë¬¸ ë°©ì§€ - ì´ë¯¸ ì–¸ê¸‰í•œ ì¦ìƒì€ ë‹¤ì‹œ ë¬»ì§€ ì•ŠìŒ")
    print("   â€¢ ì„¸ì…˜ ìƒíƒœ ê°œì„  - ì´ˆê¸° ì¦ìƒ ì •ë³´ ìœ ì§€")
    print("   â€¢ í•„í„°ë§ ë¡œì§ ê°•í™” - ë¹ˆ ê²°ê³¼ ë°©ì§€")
    print("   â€¢ ì¢…ë£Œ ì¡°ê±´ ê°œì„  - ì ì ˆí•œ ì°¨ë³„í™” ì§ˆë¬¸ ìˆ˜")
    print("="*80)
    
    # ì¸ë±ìŠ¤ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
    if PreBuiltIndexLoader.check_indexes_available():
        print("ğŸš€ ì‚¬ì „ ìƒì„±ëœ ì¸ë±ìŠ¤ ë°œê²¬! ë¹ ë¥¸ ë¡œë”©ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        index_info = PreBuiltIndexLoader.get_index_info()
        if index_info:
            print(f"ğŸ“Š ì¸ë±ìŠ¤ ìƒì„±ì¼: {index_info.get('created_at', 'Unknown')}")
    else:
        print("âš ï¸ ì‚¬ì „ ìƒì„±ëœ ì¸ë±ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. ì‹¤ì‹œê°„ ìƒì„± ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
        print("ğŸ’¡ ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•´ ë¨¼ì € generate_faiss_indexes.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”!")
    
    try:
        # ğŸš€ ìˆ˜ì •ëœ í†µí•© ì±„íŒ… ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        chat_service = OptimizedIntegratedChatServiceV6()
        
        # ğŸ“ ì„¸ì…˜ ìƒì„±
        session = IntegratedSession()
        
        print("\nğŸ’¡ í…ŒìŠ¤íŠ¸ ì˜ˆì‹œ:")
        print("1. 'ë¨¸ë¦¬ê°€ ì•„í”„ê³  ì—´ì´ ë‚˜ìš”' (ì§ˆë³‘ ì§„ë‹¨ â†’ ìŠ¤ë§ˆíŠ¸í•œ ì°¨ë³„í™” ì§ˆë¬¸)")
        print("2. 'ì–´ë–¤ ì•½ ë¨¹ì–´ì•¼ í•´?' (ì§ˆë³‘ ì§„ë‹¨ í›„ â†’ ì˜ì•½í’ˆ ì¶”ì²œ)")
        print("3. 'ë¨¸ë¦¬ ì•„í”ˆë° ë¬´ìŠ¨ ì•½?' (ë³µí•© ì˜ë„ â†’ ì˜ì•½í’ˆ ì¶”ì²œ)")
        print("4. 'ê°ê¸°ì— ëŒ€í•´ ì•Œë ¤ì¤˜' (ì§ˆë³‘ ì •ë³´ â†’ RAG ê¸°ë°˜ ê²€ìƒ‰)")
        print("5. 'íƒ€ì´ë ˆë†€ ë¶€ì‘ìš©ì´ ë­ì•¼?' (ì˜ì•½í’ˆ ì •ë³´)")
        print("6. 'ì²˜ìŒìœ¼ë¡œ' (ì„¸ì…˜ ì´ˆê¸°í™”)")
        print("7. 'exit' (ì¢…ë£Œ)")
        print("\n**ì¤‘ìš”:** ì˜ë£Œì§„ê³¼ì˜ ìƒë‹´ì„ ëŒ€ì²´í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("\nğŸš€ ëŒ€í™”ë¥¼ ì‹œì‘í•˜ì„¸ìš”!")
        
        while True:
            user_input = input("\nì‚¬ìš©ì> ").strip()
            
            if not user_input:
                continue
            
            if user_input.lower() in ['exit', 'quit', 'ì¢…ë£Œ']:
                print("ì˜ë£Œ ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            
            # ğŸ”¥ ë©”ì‹œì§€ ì²˜ë¦¬
            response = chat_service.process_message(user_input, session)
            print(f"\nì±—ë´‡> {response}")
            
            # ğŸ” ë””ë²„ê·¸ ì •ë³´ (ì„ íƒì )
            if user_input.lower() == "debug":
                print(f"\nğŸ”¬ ë””ë²„ê·¸ ì •ë³´:")
                print(f"   - ì„¸ì…˜ ID: {session.session_id}")
                print(f"   - ìµœê·¼ ì§„ë‹¨: {session.get_recent_diagnosis()}")
                print(f"   - ì§ˆë¬¸ ëª¨ë“œ: {session.context['questioning_state']['is_questioning']}")
                print(f"   - ì´ˆê¸° ì¦ìƒ: {session.context.get('initial_symptoms_text', 'None')}")
                print(f"   - ì–¸ê¸‰ëœ ì¦ìƒ: {session.context.get('mentioned_symptoms', [])}")
                print(f"   - ëŒ€í™” ìˆ˜: {len(session.history)}")
                print(f"   - ì‚¬ì „ ìƒì„± ì¸ë±ìŠ¤ ì‚¬ìš©: {chat_service.rag_manager.use_prebuilt}")
            
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        traceback.print_exc()

if __name__ == "__main__":
    main()
# backend/app/llm/api/__init__.py
"""
LLM API ì—”ë“œí¬ì¸íŠ¸ ëª¨ë“ˆ

ğŸ“¡ êµ¬ì¡°:
- chat_models.py: Pydantic ëª¨ë¸ ì •ì˜ (ChatRequest, ChatResponse ë“±)
- chat_api.py: FastAPI ë¼ìš°í„° ì •ì˜ (ì‹¤ì œ ì—”ë“œí¬ì¸íŠ¸)

ğŸ”§ ìˆ˜ì •ì‚¬í•­:
- ëª¨ë¸ì€ chat_models.pyì—ì„œ, ë¼ìš°í„°ëŠ” chat_api.pyì—ì„œ import
- integrated_chat_service.pyì—ì„œ ëª¨ë¸ë“¤ì— ì ‘ê·¼ ê°€ëŠ¥í•˜ë„ë¡ êµ¬ì„±
"""

# ğŸ“‹ ëª¨ë¸ë“¤ import (chat_models.pyì—ì„œ)
from .chat_models import (
    ChatRequest,
    ChatResponse, 
    SessionContext,
    QuestioningState,
    UserProfile,
    IntentType,
    SimpleResponse,
    create_error_response,
    create_success_response
)

# ğŸ“¡ ë¼ìš°í„° import (chat_models.pyì—ì„œ)
from .chat_models import router as chat_router

# ğŸ“¦ ì™¸ë¶€ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  ìš”ì†Œë“¤
__all__ = [
    # ë¼ìš°í„°
    "chat_router",
    
    # ëª¨ë¸ í´ë˜ìŠ¤ë“¤
    "ChatRequest",
    "ChatResponse",
    "SessionContext", 
    "QuestioningState",
    "UserProfile",
    "IntentType",
    "SimpleResponse",
    
    # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
    "create_error_response",
    "create_success_response"
]